{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Download saved model from Hugging Face\n",
    "you can either download the models you want individually or the entire thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = 'davidbzyk/simpler-gemma-2-2b-multi'\n",
    "base_model='simpler-gemma-2-2b'\n",
    "quantization_types = ['Q4_K_M', 'Q5_K_M', 'Q8_0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = './simpler-gemma-2-2b-multi'\n",
    "destination_dir = './models'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = f\"git clone https://hf.co/{repo}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory to store the models you want from the main repo\n",
    "- this for loop creates the directories, new names, and creates ollama models (you can do seperately per below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Ensure the destination directory exists\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "for quant in quantization_types:\n",
    "    # Create the new directory\n",
    "    new_dir_name = f\"{base_model}_{quant}\"\n",
    "    new_dir_path = os.path.join(destination_dir, new_dir_name)\n",
    "    os.makedirs(new_dir_path, exist_ok=True)\n",
    "    \n",
    "    # Rename the file and move it to the new directory\n",
    "    original_file_name = f\"unsloth.{quant}.gguf\"\n",
    "    new_file_name = f\"{base_model}_{quant}.gguf\"\n",
    "    \n",
    "    original_file_path = os.path.join(source_dir, original_file_name)\n",
    "    new_file_path = os.path.join(new_dir_path, new_file_name)\n",
    "    \n",
    "    if os.path.exists(original_file_path):\n",
    "        os.rename(original_file_path, new_file_path)\n",
    "    \n",
    "        # Create the modelfile with the specified content\n",
    "        modelfile_path = os.path.join(new_dir_path, 'modelfile')\n",
    "        with open(modelfile_path, 'w') as modelfile:\n",
    "            modelfile.write(f\"FROM {new_file_name}\\n\")\n",
    "    \n",
    "        print(f\"Processed: {new_file_name} -> {new_dir_path}\")\n",
    "        \n",
    "        # Slice the new_file_name to exclude the .gguf extension\n",
    "        model_name_without_extension = new_file_name[:-5]\n",
    "        \n",
    "        # Run the ollama create command\n",
    "        command = f\"ollama create {model_name_without_extension[4:]} -f {new_dir_path}/modelfile\"\n",
    "        os.system(command)\n",
    "    else:\n",
    "        print(f\"File not found: {original_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just change the variables to actual directory and names of models.. you need to put a model file in each directory\n",
    "which you can customize, but for this example we will keep it simple and do \n",
    "```python\n",
    "FROM {INSERT FULL NAME OF MODEL INCLUDING .GGUF}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama create simpler-gemma-2-2b-q5_0 -f ./simpler-gemma-2-2b-Q5_0.gguf/modelfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Old Model\n",
    "```bash\n",
    "\n",
    "model=\"llama3vbt\" && ollama list | grep -q \"$model\" && ollama rm \"$model\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
