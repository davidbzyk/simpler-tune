{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import wandb\n",
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, TrainerCallback, TrainerState, TrainerControl, EarlyStoppingCallback\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGING_FACE_HUB_TOKEN=os.getenv(\"HUGGING_FACE_HUB_TOKEN\")\n",
    "WANDB_API_KEY=os.getenv(\"WANDB_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find Simpler-Trading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdelraycapitalmanagement\u001b[0m (\u001b[33mdavidbzyk\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/dave/Desktop/simpler/simpler-prod-qa/Step-2-Training/step2b-finetune/wandb/run-20240804_130037-yzcqw95v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/davidbzyk/Simpler/runs/yzcqw95v' target=\"_blank\">dazzling-salad-13</a></strong> to <a href='https://wandb.ai/davidbzyk/Simpler' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/davidbzyk/Simpler' target=\"_blank\">https://wandb.ai/davidbzyk/Simpler</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/davidbzyk/Simpler/runs/yzcqw95v' target=\"_blank\">https://wandb.ai/davidbzyk/Simpler/runs/yzcqw95v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/davidbzyk/Simpler/runs/yzcqw95v?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ebc9cf380d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize wandb\n",
    "wandb.init(project=\"simpler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to pull your own repo/model you saved in previous step.\n",
    "```python\n",
    "##USE THIS FOR FIRST TIME TRAINING OR PICK ANOTHER SMALL MODEL FROM https://huggingface.co/unsloth\n",
    "#MODEL_NAME=\"unsloth/gemma-2-2b-it-bnb-4bit\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'davidbzyk/simpler-gemma-2-2b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA_PATH ='../../Step-1-Data-Processing/finetuning/all-qa-final.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: If you want to finetune Gemma 2, install flash-attn to make it faster!\n",
      "To install flash-attn, do the below:\n",
      "\n",
      "pip install --no-deps --upgrade \"flash-attn>=2.6.3\"\n",
      "==((====))==  Unsloth 2024.8: Fast Gemma2 patching. Transformers = 4.43.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.668 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.1. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2052418bdf4a99a574b9719e5d3e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/5.38G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.8 patched 26 layers with 26 QKV layers, 26 O layers and 26 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(    \n",
    "    model_name = MODEL_NAME,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_texts(question, answer):\n",
    "    return {\n",
    "        \"text\": f\"###{question}@@@{answer}{EOS_TOKEN}\",\n",
    "    }\n",
    "\n",
    "def load_data_from_jsonl(file_path):\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            for line_number, line in enumerate(f, start=1):\n",
    "                if line.strip():  # Skip empty lines\n",
    "                    try:\n",
    "                        entry = json.loads(line)\n",
    "                        questions.append(entry['question'])\n",
    "                        answers.append(entry['answer'])\n",
    "                        print(f\"Successfully parsed line {line_number}\")\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"Error decoding JSON on line {line_number}: {e}\")\n",
    "                        print(f\"Problematic line: {line}\")\n",
    "                    except KeyError as e:\n",
    "                        print(f\"Missing key in JSON entry on line {line_number}: {e}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Unexpected error while reading the file: {e}\")\n",
    "    \n",
    "    return questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully parsed line 1\n",
      "Successfully parsed line 2\n",
      "Successfully parsed line 3\n",
      "Successfully parsed line 4\n",
      "Successfully parsed line 5\n",
      "Successfully parsed line 6\n",
      "Successfully parsed line 7\n",
      "Successfully parsed line 8\n",
      "Successfully parsed line 9\n",
      "Successfully parsed line 10\n",
      "Successfully parsed line 11\n",
      "Successfully parsed line 12\n",
      "Successfully parsed line 13\n",
      "Successfully parsed line 14\n",
      "Successfully parsed line 15\n",
      "Successfully parsed line 16\n",
      "Successfully parsed line 17\n",
      "Successfully parsed line 18\n",
      "Successfully parsed line 19\n",
      "Successfully parsed line 20\n",
      "Successfully parsed line 21\n",
      "Successfully parsed line 22\n",
      "Successfully parsed line 23\n",
      "Successfully parsed line 24\n",
      "Successfully parsed line 25\n",
      "Successfully parsed line 26\n",
      "Successfully parsed line 27\n",
      "Successfully parsed line 28\n",
      "Successfully parsed line 29\n",
      "Successfully parsed line 30\n",
      "Successfully parsed line 31\n",
      "Successfully parsed line 32\n",
      "Successfully parsed line 33\n",
      "Successfully parsed line 34\n",
      "Successfully parsed line 35\n",
      "Successfully parsed line 36\n",
      "Successfully parsed line 37\n",
      "Successfully parsed line 38\n",
      "Successfully parsed line 39\n",
      "Successfully parsed line 40\n",
      "Successfully parsed line 41\n",
      "Successfully parsed line 42\n",
      "Successfully parsed line 43\n",
      "Successfully parsed line 44\n",
      "Successfully parsed line 45\n",
      "Successfully parsed line 46\n",
      "Successfully parsed line 47\n",
      "Successfully parsed line 48\n",
      "Successfully parsed line 49\n",
      "Successfully parsed line 50\n",
      "Successfully parsed line 51\n",
      "Successfully parsed line 52\n",
      "Successfully parsed line 53\n",
      "Successfully parsed line 54\n",
      "Successfully parsed line 55\n",
      "Successfully parsed line 56\n",
      "Successfully parsed line 57\n",
      "Successfully parsed line 58\n",
      "Successfully parsed line 59\n",
      "Successfully parsed line 60\n",
      "Successfully parsed line 61\n",
      "Successfully parsed line 62\n",
      "Successfully parsed line 63\n",
      "Successfully parsed line 64\n",
      "Successfully parsed line 65\n",
      "Successfully parsed line 66\n",
      "Successfully parsed line 67\n",
      "Successfully parsed line 68\n",
      "Successfully parsed line 69\n",
      "Successfully parsed line 70\n",
      "Successfully parsed line 71\n",
      "Successfully parsed line 72\n",
      "Successfully parsed line 73\n",
      "Successfully parsed line 74\n",
      "Successfully parsed line 75\n",
      "Successfully parsed line 76\n",
      "Successfully parsed line 77\n",
      "Successfully parsed line 78\n",
      "Successfully parsed line 79\n",
      "Successfully parsed line 80\n",
      "Successfully parsed line 81\n",
      "Successfully parsed line 82\n",
      "Successfully parsed line 83\n",
      "Successfully parsed line 84\n",
      "Successfully parsed line 85\n",
      "Successfully parsed line 86\n",
      "Successfully parsed line 87\n",
      "Successfully parsed line 88\n",
      "Successfully parsed line 89\n",
      "Successfully parsed line 90\n",
      "Successfully parsed line 91\n",
      "Successfully parsed line 92\n",
      "Successfully parsed line 93\n",
      "Successfully parsed line 94\n",
      "Successfully parsed line 95\n",
      "Successfully parsed line 96\n",
      "Successfully parsed line 97\n",
      "Successfully parsed line 98\n",
      "Successfully parsed line 99\n",
      "Successfully parsed line 100\n",
      "Successfully parsed line 101\n",
      "Successfully parsed line 102\n",
      "Successfully parsed line 103\n",
      "Successfully parsed line 104\n",
      "Successfully parsed line 105\n",
      "Successfully parsed line 106\n",
      "Successfully parsed line 107\n",
      "Successfully parsed line 108\n",
      "Successfully parsed line 109\n",
      "Successfully parsed line 110\n",
      "Successfully parsed line 111\n",
      "Successfully parsed line 112\n",
      "Successfully parsed line 113\n",
      "Successfully parsed line 114\n",
      "Successfully parsed line 115\n",
      "Successfully parsed line 116\n",
      "Successfully parsed line 117\n",
      "Successfully parsed line 118\n",
      "Successfully parsed line 119\n",
      "Successfully parsed line 120\n",
      "Successfully parsed line 121\n",
      "Successfully parsed line 122\n",
      "Successfully parsed line 123\n",
      "Successfully parsed line 124\n",
      "Successfully parsed line 125\n",
      "Successfully parsed line 126\n",
      "Successfully parsed line 127\n",
      "Successfully parsed line 128\n",
      "Successfully parsed line 129\n",
      "Successfully parsed line 130\n",
      "Successfully parsed line 131\n",
      "Successfully parsed line 132\n",
      "Successfully parsed line 133\n",
      "Successfully parsed line 134\n",
      "Successfully parsed line 135\n",
      "Successfully parsed line 136\n",
      "Successfully parsed line 137\n",
      "Successfully parsed line 138\n",
      "Successfully parsed line 139\n",
      "Successfully parsed line 140\n",
      "Successfully parsed line 141\n",
      "Successfully parsed line 142\n",
      "Successfully parsed line 143\n",
      "Successfully parsed line 144\n",
      "Successfully parsed line 145\n",
      "Successfully parsed line 146\n",
      "Successfully parsed line 147\n",
      "Successfully parsed line 148\n",
      "Successfully parsed line 149\n",
      "Successfully parsed line 150\n",
      "Successfully parsed line 151\n",
      "Successfully parsed line 152\n",
      "Successfully parsed line 153\n",
      "Successfully parsed line 154\n",
      "Successfully parsed line 155\n",
      "Successfully parsed line 156\n",
      "Successfully parsed line 157\n",
      "Successfully parsed line 158\n",
      "Successfully parsed line 159\n",
      "Successfully parsed line 160\n",
      "Successfully parsed line 161\n",
      "Successfully parsed line 162\n",
      "Successfully parsed line 163\n",
      "Successfully parsed line 164\n",
      "Successfully parsed line 165\n",
      "Successfully parsed line 166\n",
      "Successfully parsed line 167\n",
      "Successfully parsed line 168\n",
      "Successfully parsed line 169\n",
      "Successfully parsed line 170\n",
      "Successfully parsed line 171\n",
      "Successfully parsed line 172\n",
      "Successfully parsed line 173\n",
      "Successfully parsed line 174\n",
      "Successfully parsed line 175\n",
      "Successfully parsed line 176\n",
      "Successfully parsed line 177\n",
      "Successfully parsed line 178\n",
      "Successfully parsed line 179\n",
      "Successfully parsed line 180\n",
      "Successfully parsed line 181\n",
      "Successfully parsed line 182\n",
      "Successfully parsed line 183\n",
      "Successfully parsed line 184\n",
      "Successfully parsed line 185\n",
      "Successfully parsed line 186\n",
      "Successfully parsed line 187\n",
      "Successfully parsed line 188\n",
      "Successfully parsed line 189\n",
      "Successfully parsed line 190\n",
      "Successfully parsed line 191\n",
      "Successfully parsed line 192\n",
      "Successfully parsed line 193\n",
      "Successfully parsed line 194\n",
      "Successfully parsed line 195\n",
      "Successfully parsed line 196\n",
      "Successfully parsed line 197\n",
      "Successfully parsed line 198\n",
      "Successfully parsed line 199\n",
      "Successfully parsed line 200\n",
      "Successfully parsed line 201\n",
      "Successfully parsed line 202\n",
      "Successfully parsed line 203\n",
      "Successfully parsed line 204\n",
      "Successfully parsed line 205\n",
      "Successfully parsed line 206\n",
      "Successfully parsed line 207\n",
      "Successfully parsed line 208\n",
      "Successfully parsed line 209\n",
      "Successfully parsed line 210\n",
      "Successfully parsed line 211\n",
      "Successfully parsed line 212\n",
      "Successfully parsed line 213\n",
      "Successfully parsed line 214\n",
      "Successfully parsed line 215\n",
      "Successfully parsed line 216\n",
      "Successfully parsed line 217\n",
      "Successfully parsed line 218\n",
      "Successfully parsed line 219\n",
      "Successfully parsed line 220\n",
      "Successfully parsed line 221\n",
      "Successfully parsed line 222\n",
      "Successfully parsed line 223\n",
      "Successfully parsed line 224\n",
      "Successfully parsed line 225\n",
      "Successfully parsed line 226\n",
      "Successfully parsed line 227\n",
      "Successfully parsed line 228\n",
      "Successfully parsed line 229\n",
      "Successfully parsed line 230\n",
      "Successfully parsed line 231\n",
      "Successfully parsed line 232\n",
      "Successfully parsed line 233\n",
      "Successfully parsed line 234\n",
      "Successfully parsed line 235\n",
      "Successfully parsed line 236\n",
      "Successfully parsed line 237\n",
      "Successfully parsed line 238\n",
      "Successfully parsed line 239\n",
      "Successfully parsed line 240\n",
      "Successfully parsed line 241\n",
      "Successfully parsed line 242\n",
      "Successfully parsed line 243\n",
      "Successfully parsed line 244\n",
      "Successfully parsed line 245\n",
      "Successfully parsed line 246\n",
      "Successfully parsed line 247\n",
      "Successfully parsed line 248\n",
      "Successfully parsed line 249\n",
      "Successfully parsed line 250\n",
      "Successfully parsed line 251\n",
      "Successfully parsed line 252\n",
      "Successfully parsed line 253\n",
      "Successfully parsed line 254\n",
      "Successfully parsed line 255\n",
      "Successfully parsed line 256\n",
      "Successfully parsed line 257\n",
      "Successfully parsed line 258\n",
      "Successfully parsed line 259\n",
      "Successfully parsed line 260\n",
      "Successfully parsed line 261\n",
      "Successfully parsed line 262\n",
      "Successfully parsed line 263\n",
      "Successfully parsed line 264\n",
      "Successfully parsed line 265\n",
      "Successfully parsed line 266\n",
      "Successfully parsed line 267\n",
      "Successfully parsed line 268\n",
      "Successfully parsed line 269\n",
      "Successfully parsed line 270\n",
      "Successfully parsed line 271\n",
      "Successfully parsed line 272\n",
      "Successfully parsed line 273\n",
      "Successfully parsed line 274\n",
      "Successfully parsed line 275\n",
      "Successfully parsed line 276\n",
      "Successfully parsed line 277\n",
      "Successfully parsed line 278\n",
      "Successfully parsed line 279\n",
      "Successfully parsed line 280\n",
      "Successfully parsed line 281\n",
      "Successfully parsed line 282\n",
      "Successfully parsed line 283\n",
      "Successfully parsed line 284\n",
      "Successfully parsed line 285\n",
      "Successfully parsed line 286\n",
      "Successfully parsed line 287\n",
      "Successfully parsed line 288\n",
      "Successfully parsed line 289\n",
      "Successfully parsed line 290\n",
      "Successfully parsed line 291\n",
      "Successfully parsed line 292\n",
      "Successfully parsed line 293\n",
      "Successfully parsed line 294\n",
      "Successfully parsed line 295\n",
      "Successfully parsed line 296\n",
      "Successfully parsed line 297\n",
      "Successfully parsed line 298\n",
      "Successfully parsed line 299\n",
      "Successfully parsed line 300\n",
      "Successfully parsed line 301\n",
      "Successfully parsed line 302\n",
      "Successfully parsed line 303\n",
      "Successfully parsed line 304\n",
      "Successfully parsed line 305\n",
      "Successfully parsed line 306\n",
      "Successfully parsed line 307\n",
      "Successfully parsed line 308\n",
      "Successfully parsed line 309\n",
      "Successfully parsed line 310\n",
      "Successfully parsed line 311\n",
      "Successfully parsed line 312\n",
      "Successfully parsed line 313\n",
      "Successfully parsed line 314\n",
      "Successfully parsed line 315\n",
      "Successfully parsed line 316\n",
      "Successfully parsed line 317\n",
      "Successfully parsed line 318\n",
      "Successfully parsed line 319\n",
      "Successfully parsed line 320\n",
      "Successfully parsed line 321\n",
      "Successfully parsed line 322\n",
      "Successfully parsed line 323\n",
      "Successfully parsed line 324\n",
      "Successfully parsed line 325\n",
      "Successfully parsed line 326\n",
      "Successfully parsed line 327\n",
      "Successfully parsed line 328\n",
      "Successfully parsed line 329\n",
      "Successfully parsed line 330\n",
      "Successfully parsed line 331\n",
      "Successfully parsed line 332\n",
      "Successfully parsed line 333\n",
      "Successfully parsed line 334\n",
      "Successfully parsed line 335\n",
      "Successfully parsed line 336\n",
      "Successfully parsed line 337\n",
      "Successfully parsed line 338\n",
      "Successfully parsed line 339\n",
      "Successfully parsed line 340\n",
      "Successfully parsed line 341\n",
      "Successfully parsed line 342\n",
      "Successfully parsed line 343\n",
      "Successfully parsed line 344\n",
      "Successfully parsed line 345\n",
      "Successfully parsed line 346\n",
      "Successfully parsed line 347\n",
      "Successfully parsed line 348\n",
      "Successfully parsed line 349\n",
      "Successfully parsed line 350\n",
      "Successfully parsed line 351\n",
      "Successfully parsed line 352\n",
      "Successfully parsed line 353\n",
      "Successfully parsed line 354\n",
      "Successfully parsed line 355\n",
      "Successfully parsed line 356\n",
      "Successfully parsed line 357\n",
      "Successfully parsed line 358\n",
      "Successfully parsed line 359\n",
      "Successfully parsed line 360\n",
      "Successfully parsed line 361\n",
      "Successfully parsed line 362\n",
      "Successfully parsed line 363\n",
      "Successfully parsed line 364\n",
      "Successfully parsed line 365\n",
      "Successfully parsed line 366\n",
      "Successfully parsed line 367\n",
      "Successfully parsed line 368\n",
      "Successfully parsed line 369\n",
      "Successfully parsed line 370\n",
      "Successfully parsed line 371\n",
      "Successfully parsed line 372\n",
      "Successfully parsed line 373\n",
      "Successfully parsed line 374\n",
      "Successfully parsed line 375\n",
      "Successfully parsed line 376\n",
      "Successfully parsed line 377\n",
      "Successfully parsed line 378\n",
      "Successfully parsed line 379\n",
      "Successfully parsed line 380\n",
      "Successfully parsed line 381\n",
      "Successfully parsed line 382\n",
      "Successfully parsed line 383\n",
      "Successfully parsed line 384\n",
      "Successfully parsed line 385\n",
      "Successfully parsed line 386\n",
      "Successfully parsed line 387\n",
      "Successfully parsed line 388\n",
      "Successfully parsed line 389\n",
      "Successfully parsed line 390\n",
      "Successfully parsed line 391\n",
      "Successfully parsed line 392\n",
      "Successfully parsed line 393\n",
      "Successfully parsed line 394\n",
      "Successfully parsed line 395\n",
      "Successfully parsed line 396\n",
      "Successfully parsed line 397\n",
      "Successfully parsed line 398\n",
      "Successfully parsed line 399\n",
      "Successfully parsed line 400\n",
      "Successfully parsed line 401\n",
      "Successfully parsed line 402\n",
      "Successfully parsed line 403\n",
      "Successfully parsed line 404\n",
      "Successfully parsed line 405\n",
      "Successfully parsed line 406\n",
      "Successfully parsed line 407\n",
      "Successfully parsed line 408\n",
      "Successfully parsed line 409\n",
      "Successfully parsed line 410\n",
      "Successfully parsed line 411\n",
      "Successfully parsed line 412\n",
      "Successfully parsed line 413\n",
      "Successfully parsed line 414\n",
      "Successfully parsed line 415\n",
      "Successfully parsed line 416\n",
      "Successfully parsed line 417\n",
      "Successfully parsed line 418\n",
      "Successfully parsed line 419\n",
      "Successfully parsed line 420\n",
      "Successfully parsed line 421\n",
      "Successfully parsed line 422\n",
      "Successfully parsed line 423\n",
      "Successfully parsed line 424\n",
      "Successfully parsed line 425\n",
      "Successfully parsed line 426\n",
      "Successfully parsed line 427\n",
      "Successfully parsed line 428\n",
      "Successfully parsed line 429\n",
      "Successfully parsed line 430\n",
      "Successfully parsed line 431\n",
      "Successfully parsed line 432\n",
      "Successfully parsed line 433\n",
      "Successfully parsed line 434\n",
      "Successfully parsed line 435\n",
      "Successfully parsed line 436\n",
      "Successfully parsed line 437\n",
      "Successfully parsed line 438\n",
      "Successfully parsed line 439\n",
      "Successfully parsed line 440\n",
      "Successfully parsed line 441\n",
      "Successfully parsed line 442\n",
      "Successfully parsed line 443\n",
      "Successfully parsed line 444\n",
      "Successfully parsed line 445\n",
      "Successfully parsed line 446\n",
      "Successfully parsed line 447\n",
      "Successfully parsed line 448\n",
      "Successfully parsed line 449\n",
      "Successfully parsed line 450\n",
      "Successfully parsed line 451\n",
      "Successfully parsed line 452\n",
      "Successfully parsed line 453\n",
      "Successfully parsed line 454\n",
      "Successfully parsed line 455\n",
      "Successfully parsed line 456\n",
      "Successfully parsed line 457\n",
      "Successfully parsed line 458\n",
      "Successfully parsed line 459\n",
      "Successfully parsed line 460\n",
      "Successfully parsed line 461\n",
      "Successfully parsed line 462\n",
      "Successfully parsed line 463\n",
      "Successfully parsed line 464\n",
      "Successfully parsed line 465\n",
      "Successfully parsed line 466\n",
      "Successfully parsed line 467\n",
      "Successfully parsed line 468\n",
      "Successfully parsed line 469\n",
      "Successfully parsed line 470\n",
      "Successfully parsed line 471\n",
      "Successfully parsed line 472\n",
      "Successfully parsed line 473\n",
      "Successfully parsed line 474\n",
      "Successfully parsed line 475\n",
      "Successfully parsed line 476\n",
      "Successfully parsed line 477\n",
      "Successfully parsed line 478\n",
      "Successfully parsed line 479\n",
      "Successfully parsed line 480\n",
      "Successfully parsed line 481\n",
      "Successfully parsed line 482\n",
      "Successfully parsed line 483\n",
      "Successfully parsed line 484\n",
      "Successfully parsed line 485\n",
      "Successfully parsed line 486\n",
      "Successfully parsed line 487\n",
      "Successfully parsed line 488\n",
      "Successfully parsed line 489\n",
      "Successfully parsed line 490\n",
      "Successfully parsed line 491\n",
      "Successfully parsed line 492\n",
      "Successfully parsed line 493\n",
      "Successfully parsed line 494\n",
      "Successfully parsed line 495\n",
      "Successfully parsed line 496\n",
      "Successfully parsed line 497\n",
      "Successfully parsed line 498\n",
      "Successfully parsed line 499\n",
      "Successfully parsed line 500\n",
      "Successfully parsed line 501\n",
      "Successfully parsed line 502\n",
      "Successfully parsed line 503\n",
      "Successfully parsed line 504\n",
      "Successfully parsed line 505\n",
      "Successfully parsed line 506\n",
      "Successfully parsed line 507\n",
      "Successfully parsed line 508\n",
      "Successfully parsed line 509\n",
      "Successfully parsed line 510\n",
      "Successfully parsed line 511\n",
      "Successfully parsed line 512\n",
      "Successfully parsed line 513\n",
      "Successfully parsed line 514\n",
      "Successfully parsed line 515\n",
      "Successfully parsed line 516\n",
      "Successfully parsed line 517\n",
      "Successfully parsed line 518\n",
      "Successfully parsed line 519\n",
      "Successfully parsed line 520\n",
      "Successfully parsed line 521\n",
      "Successfully parsed line 522\n",
      "Successfully parsed line 523\n",
      "Successfully parsed line 524\n",
      "Successfully parsed line 525\n",
      "Successfully parsed line 526\n",
      "Successfully parsed line 527\n",
      "Successfully parsed line 528\n",
      "Successfully parsed line 529\n",
      "Successfully parsed line 530\n",
      "Successfully parsed line 531\n",
      "Successfully parsed line 532\n",
      "Successfully parsed line 533\n",
      "Successfully parsed line 534\n",
      "Successfully parsed line 535\n",
      "Successfully parsed line 536\n",
      "Successfully parsed line 537\n",
      "Successfully parsed line 538\n",
      "Successfully parsed line 539\n",
      "Successfully parsed line 540\n",
      "Successfully parsed line 541\n",
      "Successfully parsed line 542\n",
      "Successfully parsed line 543\n",
      "Successfully parsed line 544\n",
      "Successfully parsed line 545\n",
      "Successfully parsed line 546\n",
      "Successfully parsed line 547\n",
      "Successfully parsed line 548\n",
      "Successfully parsed line 549\n",
      "Successfully parsed line 550\n",
      "Successfully parsed line 551\n",
      "Successfully parsed line 552\n",
      "Successfully parsed line 553\n",
      "Successfully parsed line 554\n",
      "Successfully parsed line 555\n",
      "Successfully parsed line 556\n",
      "Successfully parsed line 557\n",
      "Successfully parsed line 558\n",
      "Successfully parsed line 559\n",
      "Successfully parsed line 560\n",
      "Successfully parsed line 561\n",
      "Successfully parsed line 562\n",
      "Successfully parsed line 563\n",
      "Successfully parsed line 564\n",
      "Successfully parsed line 565\n",
      "Successfully parsed line 566\n",
      "Successfully parsed line 567\n",
      "Successfully parsed line 568\n",
      "Successfully parsed line 569\n",
      "Successfully parsed line 570\n",
      "Successfully parsed line 571\n",
      "Successfully parsed line 572\n",
      "Successfully parsed line 573\n",
      "Successfully parsed line 574\n",
      "Successfully parsed line 575\n",
      "Successfully parsed line 576\n",
      "Successfully parsed line 577\n",
      "Successfully parsed line 578\n",
      "Successfully parsed line 579\n",
      "Successfully parsed line 580\n",
      "Successfully parsed line 581\n",
      "Successfully parsed line 582\n",
      "Successfully parsed line 583\n",
      "Successfully parsed line 584\n",
      "Successfully parsed line 585\n",
      "Successfully parsed line 586\n",
      "Successfully parsed line 587\n",
      "Successfully parsed line 588\n",
      "Successfully parsed line 589\n",
      "Successfully parsed line 590\n",
      "Successfully parsed line 591\n",
      "Successfully parsed line 592\n",
      "Successfully parsed line 593\n",
      "Successfully parsed line 594\n",
      "Successfully parsed line 595\n",
      "Successfully parsed line 596\n",
      "Successfully parsed line 597\n",
      "Successfully parsed line 598\n",
      "Successfully parsed line 599\n",
      "Successfully parsed line 600\n",
      "Successfully parsed line 601\n",
      "Successfully parsed line 602\n",
      "Successfully parsed line 603\n",
      "Successfully parsed line 604\n",
      "Successfully parsed line 605\n",
      "Successfully parsed line 606\n",
      "Successfully parsed line 607\n",
      "Successfully parsed line 608\n",
      "Successfully parsed line 609\n",
      "Successfully parsed line 610\n",
      "Successfully parsed line 611\n",
      "Successfully parsed line 612\n",
      "Successfully parsed line 613\n",
      "Successfully parsed line 614\n",
      "Successfully parsed line 615\n",
      "Successfully parsed line 616\n",
      "Successfully parsed line 617\n",
      "Successfully parsed line 618\n",
      "Successfully parsed line 619\n",
      "Successfully parsed line 620\n",
      "Successfully parsed line 621\n",
      "Successfully parsed line 622\n",
      "Successfully parsed line 623\n",
      "Successfully parsed line 624\n",
      "Successfully parsed line 625\n",
      "Successfully parsed line 626\n",
      "Successfully parsed line 627\n",
      "Successfully parsed line 628\n",
      "Successfully parsed line 629\n",
      "Successfully parsed line 630\n",
      "Successfully parsed line 631\n",
      "Successfully parsed line 632\n",
      "Successfully parsed line 633\n",
      "Successfully parsed line 634\n",
      "Successfully parsed line 635\n",
      "Successfully parsed line 636\n",
      "Successfully parsed line 637\n",
      "Successfully parsed line 638\n",
      "Successfully parsed line 639\n",
      "Successfully parsed line 640\n",
      "Successfully parsed line 641\n",
      "Successfully parsed line 642\n",
      "Successfully parsed line 643\n",
      "Successfully parsed line 644\n",
      "Successfully parsed line 645\n",
      "Successfully parsed line 646\n",
      "Successfully parsed line 647\n",
      "Successfully parsed line 648\n",
      "Successfully parsed line 649\n",
      "Successfully parsed line 650\n",
      "Successfully parsed line 651\n",
      "Successfully parsed line 652\n",
      "Successfully parsed line 653\n",
      "Successfully parsed line 654\n",
      "Successfully parsed line 655\n",
      "Successfully parsed line 656\n",
      "Successfully parsed line 657\n",
      "Successfully parsed line 658\n",
      "Successfully parsed line 659\n",
      "Successfully parsed line 660\n",
      "Successfully parsed line 661\n",
      "Successfully parsed line 662\n",
      "Successfully parsed line 663\n",
      "Successfully parsed line 664\n",
      "Successfully parsed line 665\n",
      "Successfully parsed line 666\n",
      "Successfully parsed line 667\n",
      "Successfully parsed line 668\n",
      "Successfully parsed line 669\n",
      "Successfully parsed line 670\n",
      "Successfully parsed line 671\n",
      "Successfully parsed line 672\n",
      "Successfully parsed line 673\n",
      "Successfully parsed line 674\n",
      "Successfully parsed line 675\n",
      "Successfully parsed line 676\n",
      "Successfully parsed line 677\n",
      "Successfully parsed line 678\n",
      "Successfully parsed line 679\n",
      "Successfully parsed line 680\n",
      "Successfully parsed line 681\n",
      "Successfully parsed line 682\n",
      "Successfully parsed line 683\n",
      "Successfully parsed line 684\n",
      "Successfully parsed line 685\n",
      "Successfully parsed line 686\n",
      "Successfully parsed line 687\n",
      "Successfully parsed line 688\n",
      "Successfully parsed line 689\n",
      "Successfully parsed line 690\n",
      "Successfully parsed line 691\n",
      "Successfully parsed line 692\n",
      "Successfully parsed line 693\n",
      "Successfully parsed line 694\n",
      "Successfully parsed line 695\n",
      "Successfully parsed line 696\n",
      "Successfully parsed line 697\n",
      "Successfully parsed line 698\n",
      "Successfully parsed line 699\n",
      "Successfully parsed line 700\n",
      "Successfully parsed line 701\n",
      "Successfully parsed line 702\n",
      "Successfully parsed line 703\n",
      "Successfully parsed line 704\n",
      "Successfully parsed line 705\n",
      "Successfully parsed line 706\n",
      "Successfully parsed line 707\n",
      "Successfully parsed line 708\n",
      "Successfully parsed line 709\n",
      "Successfully parsed line 710\n",
      "Successfully parsed line 711\n",
      "Successfully parsed line 712\n",
      "Successfully parsed line 713\n",
      "Successfully parsed line 714\n",
      "Successfully parsed line 715\n",
      "Successfully parsed line 716\n",
      "Successfully parsed line 717\n",
      "Successfully parsed line 718\n",
      "Successfully parsed line 719\n",
      "Successfully parsed line 720\n",
      "Successfully parsed line 721\n",
      "Successfully parsed line 722\n",
      "Successfully parsed line 723\n",
      "Successfully parsed line 724\n",
      "Successfully parsed line 725\n",
      "Successfully parsed line 726\n",
      "Successfully parsed line 727\n",
      "Successfully parsed line 728\n",
      "Successfully parsed line 729\n",
      "Successfully parsed line 730\n",
      "Successfully parsed line 731\n",
      "Successfully parsed line 732\n",
      "Successfully parsed line 733\n",
      "Successfully parsed line 734\n",
      "Successfully parsed line 735\n",
      "Successfully parsed line 736\n",
      "Successfully parsed line 737\n",
      "Successfully parsed line 738\n",
      "Successfully parsed line 739\n",
      "Successfully parsed line 740\n",
      "Successfully parsed line 741\n",
      "Successfully parsed line 742\n",
      "Successfully parsed line 743\n",
      "Successfully parsed line 744\n",
      "Successfully parsed line 745\n",
      "Successfully parsed line 746\n",
      "Successfully parsed line 747\n",
      "Successfully parsed line 748\n",
      "Successfully parsed line 749\n",
      "Successfully parsed line 750\n",
      "Successfully parsed line 751\n",
      "Successfully parsed line 752\n",
      "Successfully parsed line 753\n",
      "Successfully parsed line 754\n",
      "Successfully parsed line 755\n",
      "Successfully parsed line 756\n",
      "Successfully parsed line 757\n",
      "Successfully parsed line 758\n",
      "Successfully parsed line 759\n",
      "Successfully parsed line 760\n",
      "Successfully parsed line 761\n",
      "Successfully parsed line 762\n",
      "Successfully parsed line 763\n",
      "Successfully parsed line 764\n",
      "Successfully parsed line 765\n",
      "Successfully parsed line 766\n",
      "Successfully parsed line 767\n",
      "Successfully parsed line 768\n",
      "Successfully parsed line 769\n",
      "Successfully parsed line 770\n",
      "Successfully parsed line 771\n",
      "Successfully parsed line 772\n",
      "Successfully parsed line 773\n",
      "Successfully parsed line 774\n",
      "Successfully parsed line 775\n",
      "Successfully parsed line 776\n",
      "Successfully parsed line 777\n",
      "Successfully parsed line 778\n",
      "Successfully parsed line 779\n",
      "Successfully parsed line 780\n",
      "Successfully parsed line 781\n",
      "Successfully parsed line 782\n",
      "Successfully parsed line 783\n",
      "Successfully parsed line 784\n",
      "Successfully parsed line 785\n",
      "Successfully parsed line 786\n",
      "Successfully parsed line 787\n",
      "Successfully parsed line 788\n",
      "Successfully parsed line 789\n",
      "Successfully parsed line 790\n",
      "Successfully parsed line 791\n",
      "Successfully parsed line 792\n",
      "Successfully parsed line 793\n",
      "Successfully parsed line 794\n",
      "Successfully parsed line 795\n",
      "Successfully parsed line 796\n",
      "Successfully parsed line 797\n",
      "Successfully parsed line 798\n",
      "Successfully parsed line 799\n",
      "Successfully parsed line 800\n",
      "Successfully parsed line 801\n",
      "Successfully parsed line 802\n",
      "Successfully parsed line 803\n",
      "Successfully parsed line 804\n",
      "Successfully parsed line 805\n",
      "Successfully parsed line 806\n",
      "Successfully parsed line 807\n",
      "Successfully parsed line 808\n",
      "Successfully parsed line 809\n",
      "Successfully parsed line 810\n",
      "Successfully parsed line 811\n",
      "Successfully parsed line 812\n",
      "Successfully parsed line 813\n",
      "Successfully parsed line 814\n",
      "Successfully parsed line 815\n",
      "Successfully parsed line 816\n",
      "Successfully parsed line 817\n",
      "Successfully parsed line 818\n",
      "Successfully parsed line 819\n",
      "Successfully parsed line 820\n",
      "Successfully parsed line 821\n",
      "Successfully parsed line 822\n",
      "Successfully parsed line 823\n",
      "Successfully parsed line 824\n",
      "Successfully parsed line 825\n",
      "Successfully parsed line 826\n",
      "Successfully parsed line 827\n",
      "Successfully parsed line 828\n",
      "Successfully parsed line 829\n",
      "Successfully parsed line 830\n",
      "Successfully parsed line 831\n",
      "Successfully parsed line 832\n",
      "Successfully parsed line 833\n",
      "Successfully parsed line 834\n",
      "Successfully parsed line 835\n",
      "Successfully parsed line 836\n",
      "Successfully parsed line 837\n",
      "Successfully parsed line 838\n",
      "Successfully parsed line 839\n",
      "Successfully parsed line 840\n",
      "Successfully parsed line 841\n",
      "Successfully parsed line 842\n",
      "Successfully parsed line 843\n",
      "Successfully parsed line 844\n",
      "Successfully parsed line 845\n",
      "Successfully parsed line 846\n",
      "Successfully parsed line 847\n",
      "Successfully parsed line 848\n",
      "Successfully parsed line 849\n",
      "Successfully parsed line 850\n",
      "Successfully parsed line 851\n",
      "Successfully parsed line 852\n",
      "Successfully parsed line 853\n",
      "Successfully parsed line 854\n",
      "Successfully parsed line 855\n",
      "Successfully parsed line 856\n",
      "Successfully parsed line 857\n",
      "Successfully parsed line 858\n",
      "Successfully parsed line 859\n",
      "Successfully parsed line 860\n",
      "Successfully parsed line 861\n",
      "Successfully parsed line 862\n",
      "Successfully parsed line 863\n",
      "Successfully parsed line 864\n",
      "Successfully parsed line 865\n",
      "Successfully parsed line 866\n",
      "Successfully parsed line 867\n",
      "Successfully parsed line 868\n",
      "Successfully parsed line 869\n",
      "Successfully parsed line 870\n",
      "Successfully parsed line 871\n",
      "Successfully parsed line 872\n",
      "Successfully parsed line 873\n",
      "Successfully parsed line 874\n",
      "Successfully parsed line 875\n",
      "Successfully parsed line 876\n",
      "Successfully parsed line 877\n",
      "Successfully parsed line 878\n",
      "Successfully parsed line 879\n",
      "Successfully parsed line 880\n",
      "Successfully parsed line 881\n",
      "Successfully parsed line 882\n",
      "Successfully parsed line 883\n",
      "Successfully parsed line 884\n",
      "Successfully parsed line 885\n",
      "Successfully parsed line 886\n",
      "Successfully parsed line 887\n",
      "Successfully parsed line 888\n",
      "Successfully parsed line 889\n",
      "Successfully parsed line 890\n",
      "Successfully parsed line 891\n",
      "Successfully parsed line 892\n",
      "Successfully parsed line 893\n",
      "Successfully parsed line 894\n",
      "Successfully parsed line 895\n",
      "Successfully parsed line 896\n",
      "Successfully parsed line 897\n",
      "Successfully parsed line 898\n",
      "Successfully parsed line 899\n",
      "Successfully parsed line 900\n",
      "Successfully parsed line 901\n",
      "Successfully parsed line 902\n",
      "Successfully parsed line 903\n",
      "Successfully parsed line 904\n",
      "Successfully parsed line 905\n",
      "Successfully parsed line 906\n",
      "Successfully parsed line 907\n",
      "Successfully parsed line 908\n",
      "Successfully parsed line 909\n",
      "Successfully parsed line 910\n",
      "Successfully parsed line 911\n",
      "Successfully parsed line 912\n",
      "Successfully parsed line 913\n",
      "Successfully parsed line 914\n",
      "Successfully parsed line 915\n",
      "Successfully parsed line 916\n",
      "Successfully parsed line 917\n",
      "Successfully parsed line 918\n",
      "Successfully parsed line 919\n",
      "Successfully parsed line 920\n",
      "Successfully parsed line 921\n",
      "Successfully parsed line 922\n",
      "Successfully parsed line 923\n",
      "Successfully parsed line 924\n",
      "Successfully parsed line 925\n",
      "Successfully parsed line 926\n",
      "Successfully parsed line 927\n",
      "Successfully parsed line 928\n",
      "Successfully parsed line 929\n",
      "Successfully parsed line 930\n",
      "Successfully parsed line 931\n",
      "Successfully parsed line 932\n",
      "Successfully parsed line 933\n",
      "Successfully parsed line 934\n",
      "Successfully parsed line 935\n",
      "Successfully parsed line 936\n",
      "Successfully parsed line 937\n",
      "Successfully parsed line 938\n",
      "Successfully parsed line 939\n",
      "Successfully parsed line 940\n",
      "Successfully parsed line 941\n",
      "Successfully parsed line 942\n",
      "Successfully parsed line 943\n",
      "Successfully parsed line 944\n",
      "Successfully parsed line 945\n",
      "Successfully parsed line 946\n",
      "Successfully parsed line 947\n",
      "Successfully parsed line 948\n",
      "Successfully parsed line 949\n",
      "Successfully parsed line 950\n",
      "Successfully parsed line 951\n",
      "Successfully parsed line 952\n",
      "Successfully parsed line 953\n",
      "Successfully parsed line 954\n",
      "Successfully parsed line 955\n",
      "Successfully parsed line 956\n",
      "Successfully parsed line 957\n",
      "Successfully parsed line 958\n",
      "Successfully parsed line 959\n",
      "Successfully parsed line 960\n",
      "Successfully parsed line 961\n",
      "Successfully parsed line 962\n",
      "Successfully parsed line 963\n",
      "Successfully parsed line 964\n",
      "Successfully parsed line 965\n",
      "Successfully parsed line 966\n",
      "Successfully parsed line 967\n",
      "Successfully parsed line 968\n",
      "Successfully parsed line 969\n",
      "Successfully parsed line 970\n",
      "Successfully parsed line 971\n",
      "Successfully parsed line 972\n",
      "Successfully parsed line 973\n",
      "Successfully parsed line 974\n",
      "Successfully parsed line 975\n",
      "Successfully parsed line 976\n",
      "Successfully parsed line 977\n",
      "Successfully parsed line 978\n",
      "Successfully parsed line 979\n",
      "Successfully parsed line 980\n",
      "Successfully parsed line 981\n",
      "Successfully parsed line 982\n",
      "Successfully parsed line 983\n",
      "Successfully parsed line 984\n",
      "Successfully parsed line 985\n",
      "Successfully parsed line 986\n",
      "Successfully parsed line 987\n",
      "Successfully parsed line 988\n",
      "Successfully parsed line 989\n",
      "Successfully parsed line 990\n",
      "Successfully parsed line 991\n",
      "Successfully parsed line 992\n",
      "Successfully parsed line 993\n",
      "Successfully parsed line 994\n",
      "Successfully parsed line 995\n",
      "Successfully parsed line 996\n",
      "Successfully parsed line 997\n",
      "Successfully parsed line 998\n",
      "Successfully parsed line 999\n",
      "Successfully parsed line 1000\n",
      "Successfully parsed line 1001\n",
      "Successfully parsed line 1002\n",
      "Successfully parsed line 1003\n",
      "Successfully parsed line 1004\n",
      "Successfully parsed line 1005\n",
      "Successfully parsed line 1006\n",
      "Successfully parsed line 1007\n",
      "Successfully parsed line 1008\n",
      "Successfully parsed line 1009\n",
      "Successfully parsed line 1010\n",
      "Successfully parsed line 1011\n",
      "Successfully parsed line 1012\n",
      "Successfully parsed line 1013\n",
      "Successfully parsed line 1014\n",
      "Successfully parsed line 1015\n",
      "Successfully parsed line 1016\n",
      "Successfully parsed line 1017\n",
      "Successfully parsed line 1018\n",
      "Successfully parsed line 1019\n",
      "Successfully parsed line 1020\n",
      "Successfully parsed line 1021\n",
      "Successfully parsed line 1022\n",
      "Successfully parsed line 1023\n",
      "Successfully parsed line 1024\n",
      "Successfully parsed line 1025\n",
      "Successfully parsed line 1026\n",
      "Successfully parsed line 1027\n",
      "Successfully parsed line 1028\n",
      "Successfully parsed line 1029\n",
      "Successfully parsed line 1030\n",
      "Successfully parsed line 1031\n",
      "Successfully parsed line 1032\n",
      "Successfully parsed line 1033\n",
      "Successfully parsed line 1034\n",
      "Successfully parsed line 1035\n",
      "Successfully parsed line 1036\n",
      "Successfully parsed line 1037\n",
      "Successfully parsed line 1038\n",
      "Successfully parsed line 1039\n",
      "Successfully parsed line 1040\n",
      "Successfully parsed line 1041\n",
      "Successfully parsed line 1042\n",
      "Successfully parsed line 1043\n",
      "Successfully parsed line 1044\n",
      "Successfully parsed line 1045\n",
      "Successfully parsed line 1046\n",
      "Successfully parsed line 1047\n",
      "Successfully parsed line 1048\n",
      "Successfully parsed line 1049\n",
      "Successfully parsed line 1050\n",
      "Successfully parsed line 1051\n",
      "Successfully parsed line 1052\n",
      "Successfully parsed line 1053\n",
      "Successfully parsed line 1054\n",
      "Successfully parsed line 1055\n",
      "Successfully parsed line 1056\n",
      "Successfully parsed line 1057\n",
      "Successfully parsed line 1058\n",
      "Successfully parsed line 1059\n",
      "Successfully parsed line 1060\n",
      "Successfully parsed line 1061\n",
      "Successfully parsed line 1062\n",
      "Successfully parsed line 1063\n",
      "Successfully parsed line 1064\n",
      "Successfully parsed line 1065\n",
      "Successfully parsed line 1066\n",
      "Successfully parsed line 1067\n",
      "Successfully parsed line 1068\n",
      "Successfully parsed line 1069\n",
      "Successfully parsed line 1070\n",
      "Successfully parsed line 1071\n",
      "Successfully parsed line 1072\n",
      "Successfully parsed line 1073\n",
      "Successfully parsed line 1074\n",
      "Successfully parsed line 1075\n",
      "Successfully parsed line 1076\n",
      "Successfully parsed line 1077\n",
      "Successfully parsed line 1078\n",
      "Successfully parsed line 1079\n",
      "Successfully parsed line 1080\n",
      "Successfully parsed line 1081\n",
      "Successfully parsed line 1082\n",
      "Successfully parsed line 1083\n",
      "Successfully parsed line 1084\n",
      "Successfully parsed line 1085\n",
      "Successfully parsed line 1086\n",
      "Successfully parsed line 1087\n",
      "Successfully parsed line 1088\n",
      "Successfully parsed line 1089\n",
      "Successfully parsed line 1090\n",
      "Successfully parsed line 1091\n",
      "Successfully parsed line 1092\n",
      "Successfully parsed line 1093\n",
      "Successfully parsed line 1094\n",
      "Successfully parsed line 1095\n",
      "Successfully parsed line 1096\n",
      "Successfully parsed line 1097\n",
      "Successfully parsed line 1098\n",
      "Successfully parsed line 1099\n",
      "Successfully parsed line 1100\n",
      "Successfully parsed line 1101\n",
      "Successfully parsed line 1102\n",
      "Successfully parsed line 1103\n",
      "Successfully parsed line 1104\n",
      "Successfully parsed line 1105\n",
      "Successfully parsed line 1106\n",
      "Successfully parsed line 1107\n",
      "Successfully parsed line 1108\n",
      "Successfully parsed line 1109\n",
      "Successfully parsed line 1110\n",
      "Successfully parsed line 1111\n",
      "Successfully parsed line 1112\n",
      "Successfully parsed line 1113\n",
      "Successfully parsed line 1114\n",
      "Successfully parsed line 1115\n",
      "Successfully parsed line 1116\n",
      "Successfully parsed line 1117\n",
      "Successfully parsed line 1118\n",
      "Successfully parsed line 1119\n",
      "Successfully parsed line 1120\n",
      "Successfully parsed line 1121\n",
      "Successfully parsed line 1122\n",
      "Successfully parsed line 1123\n",
      "Successfully parsed line 1124\n",
      "Successfully parsed line 1125\n",
      "Successfully parsed line 1126\n",
      "Successfully parsed line 1127\n",
      "Successfully parsed line 1128\n",
      "Successfully parsed line 1129\n",
      "Successfully parsed line 1130\n",
      "Successfully parsed line 1131\n",
      "Successfully parsed line 1132\n",
      "Successfully parsed line 1133\n",
      "Successfully parsed line 1134\n",
      "Successfully parsed line 1135\n",
      "Successfully parsed line 1136\n",
      "Successfully parsed line 1137\n",
      "Successfully parsed line 1138\n",
      "Successfully parsed line 1139\n",
      "Successfully parsed line 1140\n",
      "Successfully parsed line 1141\n",
      "Successfully parsed line 1142\n",
      "Successfully parsed line 1143\n",
      "Successfully parsed line 1144\n",
      "Successfully parsed line 1145\n",
      "Successfully parsed line 1146\n",
      "Successfully parsed line 1147\n",
      "Successfully parsed line 1148\n",
      "Successfully parsed line 1149\n",
      "Successfully parsed line 1150\n",
      "Successfully parsed line 1151\n",
      "Successfully parsed line 1152\n",
      "Successfully parsed line 1153\n",
      "Successfully parsed line 1154\n",
      "Successfully parsed line 1155\n",
      "Successfully parsed line 1156\n",
      "Successfully parsed line 1157\n",
      "Successfully parsed line 1158\n",
      "Successfully parsed line 1159\n",
      "Successfully parsed line 1160\n",
      "Successfully parsed line 1161\n",
      "Successfully parsed line 1162\n",
      "Successfully parsed line 1163\n",
      "Successfully parsed line 1164\n",
      "Successfully parsed line 1165\n",
      "Successfully parsed line 1166\n",
      "Successfully parsed line 1167\n",
      "Successfully parsed line 1168\n",
      "Successfully parsed line 1169\n",
      "Successfully parsed line 1170\n",
      "Successfully parsed line 1171\n",
      "Successfully parsed line 1172\n",
      "Successfully parsed line 1173\n",
      "Successfully parsed line 1174\n",
      "Successfully parsed line 1175\n",
      "Successfully parsed line 1176\n",
      "Successfully parsed line 1177\n",
      "Successfully parsed line 1178\n",
      "Successfully parsed line 1179\n",
      "Successfully parsed line 1180\n",
      "Successfully parsed line 1181\n",
      "Successfully parsed line 1182\n",
      "Successfully parsed line 1183\n",
      "Successfully parsed line 1184\n",
      "Successfully parsed line 1185\n",
      "Successfully parsed line 1186\n",
      "Successfully parsed line 1187\n",
      "Successfully parsed line 1188\n",
      "Successfully parsed line 1189\n",
      "Successfully parsed line 1190\n",
      "Successfully parsed line 1191\n",
      "Successfully parsed line 1192\n",
      "Successfully parsed line 1193\n",
      "Successfully parsed line 1194\n",
      "Successfully parsed line 1195\n",
      "Successfully parsed line 1196\n",
      "Successfully parsed line 1197\n",
      "Successfully parsed line 1198\n",
      "Successfully parsed line 1199\n",
      "Successfully parsed line 1200\n",
      "Successfully parsed line 1201\n",
      "Successfully parsed line 1202\n",
      "Successfully parsed line 1203\n",
      "Successfully parsed line 1204\n",
      "Successfully parsed line 1205\n",
      "Successfully parsed line 1206\n",
      "Successfully parsed line 1207\n",
      "Successfully parsed line 1208\n",
      "Successfully parsed line 1209\n",
      "Successfully parsed line 1210\n",
      "Successfully parsed line 1211\n",
      "Successfully parsed line 1212\n",
      "Successfully parsed line 1213\n",
      "Successfully parsed line 1214\n",
      "Successfully parsed line 1215\n",
      "Successfully parsed line 1216\n",
      "Successfully parsed line 1217\n",
      "Successfully parsed line 1218\n",
      "Successfully parsed line 1219\n",
      "Successfully parsed line 1220\n",
      "Successfully parsed line 1221\n",
      "Successfully parsed line 1222\n",
      "Successfully parsed line 1223\n",
      "Successfully parsed line 1224\n",
      "Successfully parsed line 1225\n",
      "Successfully parsed line 1226\n",
      "Successfully parsed line 1227\n",
      "Successfully parsed line 1228\n",
      "Successfully parsed line 1229\n",
      "Successfully parsed line 1230\n",
      "Successfully parsed line 1231\n",
      "Successfully parsed line 1232\n",
      "Successfully parsed line 1233\n",
      "Successfully parsed line 1234\n",
      "Successfully parsed line 1235\n",
      "Successfully parsed line 1236\n",
      "Successfully parsed line 1237\n",
      "Successfully parsed line 1238\n",
      "Successfully parsed line 1239\n",
      "Successfully parsed line 1240\n",
      "Successfully parsed line 1241\n",
      "Successfully parsed line 1242\n",
      "Successfully parsed line 1243\n",
      "Successfully parsed line 1244\n",
      "Successfully parsed line 1245\n",
      "Successfully parsed line 1246\n",
      "Successfully parsed line 1247\n",
      "Successfully parsed line 1248\n",
      "Successfully parsed line 1249\n",
      "Successfully parsed line 1250\n",
      "Successfully parsed line 1251\n",
      "Successfully parsed line 1252\n",
      "Successfully parsed line 1253\n",
      "Successfully parsed line 1254\n",
      "Successfully parsed line 1255\n",
      "Successfully parsed line 1256\n",
      "Successfully parsed line 1257\n",
      "Successfully parsed line 1258\n",
      "Successfully parsed line 1259\n",
      "Successfully parsed line 1260\n",
      "Successfully parsed line 1261\n",
      "Successfully parsed line 1262\n",
      "Successfully parsed line 1263\n",
      "Successfully parsed line 1264\n",
      "Successfully parsed line 1265\n",
      "Successfully parsed line 1266\n",
      "Successfully parsed line 1267\n",
      "Successfully parsed line 1268\n",
      "Successfully parsed line 1269\n",
      "Successfully parsed line 1270\n",
      "Successfully parsed line 1271\n",
      "Successfully parsed line 1272\n",
      "Successfully parsed line 1273\n",
      "Successfully parsed line 1274\n",
      "Successfully parsed line 1275\n",
      "Successfully parsed line 1276\n",
      "Successfully parsed line 1277\n",
      "Successfully parsed line 1278\n",
      "Successfully parsed line 1279\n",
      "Successfully parsed line 1280\n",
      "Successfully parsed line 1281\n",
      "Successfully parsed line 1282\n",
      "Successfully parsed line 1283\n",
      "Successfully parsed line 1284\n",
      "Successfully parsed line 1285\n",
      "Successfully parsed line 1286\n",
      "Successfully parsed line 1287\n",
      "Successfully parsed line 1288\n",
      "Successfully parsed line 1289\n",
      "Successfully parsed line 1290\n",
      "Successfully parsed line 1291\n",
      "Successfully parsed line 1292\n",
      "Successfully parsed line 1293\n",
      "Successfully parsed line 1294\n",
      "Successfully parsed line 1295\n",
      "Successfully parsed line 1296\n",
      "Successfully parsed line 1297\n",
      "Successfully parsed line 1298\n",
      "Successfully parsed line 1299\n",
      "Successfully parsed line 1300\n",
      "Successfully parsed line 1301\n",
      "Successfully parsed line 1302\n",
      "Successfully parsed line 1303\n",
      "Successfully parsed line 1304\n",
      "Successfully parsed line 1305\n",
      "Successfully parsed line 1306\n",
      "Successfully parsed line 1307\n",
      "Successfully parsed line 1308\n",
      "Successfully parsed line 1309\n",
      "Successfully parsed line 1310\n",
      "Successfully parsed line 1311\n",
      "Successfully parsed line 1312\n",
      "Successfully parsed line 1313\n",
      "Successfully parsed line 1314\n",
      "Successfully parsed line 1315\n",
      "Successfully parsed line 1316\n",
      "Successfully parsed line 1317\n",
      "Successfully parsed line 1318\n",
      "Successfully parsed line 1319\n",
      "Successfully parsed line 1320\n",
      "Successfully parsed line 1321\n",
      "Successfully parsed line 1322\n",
      "Successfully parsed line 1323\n",
      "Successfully parsed line 1324\n",
      "Successfully parsed line 1325\n",
      "Successfully parsed line 1326\n",
      "Successfully parsed line 1327\n",
      "Successfully parsed line 1328\n",
      "Successfully parsed line 1329\n",
      "Successfully parsed line 1330\n",
      "Successfully parsed line 1331\n",
      "Successfully parsed line 1332\n",
      "Successfully parsed line 1333\n",
      "Successfully parsed line 1334\n",
      "Successfully parsed line 1335\n",
      "Successfully parsed line 1336\n",
      "Successfully parsed line 1337\n",
      "Successfully parsed line 1338\n",
      "Successfully parsed line 1339\n",
      "Successfully parsed line 1340\n",
      "Successfully parsed line 1341\n",
      "Successfully parsed line 1342\n",
      "Successfully parsed line 1343\n",
      "Successfully parsed line 1344\n",
      "Successfully parsed line 1345\n",
      "Successfully parsed line 1346\n",
      "Successfully parsed line 1347\n",
      "Successfully parsed line 1348\n",
      "Successfully parsed line 1349\n",
      "Successfully parsed line 1350\n",
      "Successfully parsed line 1351\n",
      "Successfully parsed line 1352\n",
      "Successfully parsed line 1353\n",
      "Successfully parsed line 1354\n",
      "Successfully parsed line 1355\n",
      "Successfully parsed line 1356\n",
      "Successfully parsed line 1357\n",
      "Successfully parsed line 1358\n",
      "Successfully parsed line 1359\n",
      "Successfully parsed line 1360\n",
      "Successfully parsed line 1361\n",
      "Successfully parsed line 1362\n",
      "Successfully parsed line 1363\n",
      "Successfully parsed line 1364\n",
      "Successfully parsed line 1365\n",
      "Successfully parsed line 1366\n",
      "Successfully parsed line 1367\n",
      "Successfully parsed line 1368\n",
      "Successfully parsed line 1369\n",
      "Successfully parsed line 1370\n",
      "Successfully parsed line 1371\n",
      "Successfully parsed line 1372\n",
      "Successfully parsed line 1373\n",
      "Successfully parsed line 1374\n",
      "Successfully parsed line 1375\n",
      "Successfully parsed line 1376\n",
      "Successfully parsed line 1377\n",
      "Successfully parsed line 1378\n",
      "Successfully parsed line 1379\n",
      "Successfully parsed line 1380\n",
      "Successfully parsed line 1381\n",
      "Successfully parsed line 1382\n",
      "Successfully parsed line 1383\n",
      "Successfully parsed line 1384\n",
      "Successfully parsed line 1385\n",
      "Successfully parsed line 1386\n",
      "Successfully parsed line 1387\n",
      "Successfully parsed line 1388\n",
      "Successfully parsed line 1389\n",
      "Successfully parsed line 1390\n",
      "Successfully parsed line 1391\n",
      "Successfully parsed line 1392\n",
      "Successfully parsed line 1393\n",
      "Successfully parsed line 1394\n",
      "Successfully parsed line 1395\n",
      "Successfully parsed line 1396\n",
      "Successfully parsed line 1397\n",
      "Successfully parsed line 1398\n",
      "Successfully parsed line 1399\n",
      "Successfully parsed line 1400\n",
      "Successfully parsed line 1401\n",
      "Successfully parsed line 1402\n",
      "Successfully parsed line 1403\n",
      "Successfully parsed line 1404\n",
      "Successfully parsed line 1405\n",
      "Successfully parsed line 1406\n",
      "Successfully parsed line 1407\n",
      "Successfully parsed line 1408\n",
      "Successfully parsed line 1409\n",
      "Successfully parsed line 1410\n",
      "Successfully parsed line 1411\n",
      "Successfully parsed line 1412\n",
      "Successfully parsed line 1413\n",
      "Successfully parsed line 1414\n",
      "Successfully parsed line 1415\n",
      "Successfully parsed line 1416\n",
      "Successfully parsed line 1417\n",
      "Successfully parsed line 1418\n",
      "Successfully parsed line 1419\n",
      "Successfully parsed line 1420\n",
      "Successfully parsed line 1421\n",
      "Successfully parsed line 1422\n",
      "Successfully parsed line 1423\n",
      "Successfully parsed line 1424\n",
      "Successfully parsed line 1425\n",
      "Successfully parsed line 1426\n",
      "Successfully parsed line 1427\n",
      "Successfully parsed line 1428\n",
      "Successfully parsed line 1429\n",
      "Successfully parsed line 1430\n",
      "Successfully parsed line 1431\n",
      "Successfully parsed line 1432\n",
      "Successfully parsed line 1433\n",
      "Successfully parsed line 1434\n",
      "Successfully parsed line 1435\n",
      "Successfully parsed line 1436\n",
      "Successfully parsed line 1437\n",
      "Successfully parsed line 1438\n",
      "Successfully parsed line 1439\n",
      "Successfully parsed line 1440\n",
      "Successfully parsed line 1441\n",
      "Successfully parsed line 1442\n",
      "Successfully parsed line 1443\n",
      "Successfully parsed line 1444\n",
      "Successfully parsed line 1445\n",
      "Successfully parsed line 1446\n",
      "Successfully parsed line 1447\n",
      "Successfully parsed line 1448\n",
      "Successfully parsed line 1449\n",
      "Successfully parsed line 1450\n",
      "Successfully parsed line 1451\n",
      "Successfully parsed line 1452\n",
      "Successfully parsed line 1453\n",
      "Successfully parsed line 1454\n",
      "Successfully parsed line 1455\n",
      "Successfully parsed line 1456\n",
      "Successfully parsed line 1457\n",
      "Successfully parsed line 1458\n",
      "Successfully parsed line 1459\n",
      "Successfully parsed line 1460\n",
      "Successfully parsed line 1461\n",
      "Successfully parsed line 1462\n",
      "Successfully parsed line 1463\n",
      "Successfully parsed line 1464\n",
      "Successfully parsed line 1465\n",
      "Successfully parsed line 1466\n",
      "Successfully parsed line 1467\n",
      "Successfully parsed line 1468\n",
      "Successfully parsed line 1469\n",
      "Successfully parsed line 1470\n",
      "Successfully parsed line 1471\n",
      "Successfully parsed line 1472\n",
      "Successfully parsed line 1473\n",
      "Successfully parsed line 1474\n",
      "Successfully parsed line 1475\n",
      "Successfully parsed line 1476\n",
      "Successfully parsed line 1477\n",
      "Successfully parsed line 1478\n",
      "Successfully parsed line 1479\n",
      "Successfully parsed line 1480\n",
      "Successfully parsed line 1481\n",
      "Successfully parsed line 1482\n",
      "Successfully parsed line 1483\n",
      "Successfully parsed line 1484\n",
      "Successfully parsed line 1485\n",
      "Successfully parsed line 1486\n",
      "Successfully parsed line 1487\n",
      "Successfully parsed line 1488\n",
      "Successfully parsed line 1489\n",
      "Successfully parsed line 1490\n",
      "Successfully parsed line 1491\n",
      "Successfully parsed line 1492\n",
      "Successfully parsed line 1493\n",
      "Successfully parsed line 1494\n",
      "Successfully parsed line 1495\n",
      "Successfully parsed line 1496\n",
      "Successfully parsed line 1497\n",
      "Successfully parsed line 1498\n",
      "Successfully parsed line 1499\n",
      "Successfully parsed line 1500\n",
      "Successfully parsed line 1501\n",
      "Successfully parsed line 1502\n",
      "Successfully parsed line 1503\n",
      "Successfully parsed line 1504\n",
      "Successfully parsed line 1505\n",
      "Successfully parsed line 1506\n",
      "Successfully parsed line 1507\n",
      "Successfully parsed line 1508\n",
      "Successfully parsed line 1509\n",
      "Successfully parsed line 1510\n",
      "Successfully parsed line 1511\n",
      "Successfully parsed line 1512\n",
      "Successfully parsed line 1513\n",
      "Successfully parsed line 1514\n",
      "Successfully parsed line 1515\n",
      "Successfully parsed line 1516\n",
      "Successfully parsed line 1517\n",
      "Successfully parsed line 1518\n",
      "Successfully parsed line 1519\n",
      "Successfully parsed line 1520\n",
      "Successfully parsed line 1521\n",
      "Successfully parsed line 1522\n",
      "Successfully parsed line 1523\n",
      "Successfully parsed line 1524\n",
      "Successfully parsed line 1525\n",
      "Successfully parsed line 1526\n",
      "Successfully parsed line 1527\n",
      "Successfully parsed line 1528\n",
      "Successfully parsed line 1529\n",
      "Successfully parsed line 1530\n",
      "Successfully parsed line 1531\n",
      "Successfully parsed line 1532\n",
      "Successfully parsed line 1533\n",
      "Successfully parsed line 1534\n",
      "Successfully parsed line 1535\n",
      "Successfully parsed line 1536\n",
      "Successfully parsed line 1537\n",
      "Successfully parsed line 1538\n",
      "Successfully parsed line 1539\n",
      "Successfully parsed line 1540\n",
      "Successfully parsed line 1541\n",
      "Successfully parsed line 1542\n",
      "Successfully parsed line 1543\n",
      "Successfully parsed line 1544\n",
      "Successfully parsed line 1545\n",
      "Successfully parsed line 1546\n",
      "Successfully parsed line 1547\n",
      "Successfully parsed line 1548\n",
      "Successfully parsed line 1549\n",
      "Successfully parsed line 1550\n",
      "Successfully parsed line 1551\n",
      "Successfully parsed line 1552\n",
      "Successfully parsed line 1553\n",
      "Successfully parsed line 1554\n",
      "Successfully parsed line 1555\n",
      "Successfully parsed line 1556\n",
      "Successfully parsed line 1557\n",
      "Successfully parsed line 1558\n",
      "Successfully parsed line 1559\n",
      "Successfully parsed line 1560\n",
      "Successfully parsed line 1561\n",
      "Successfully parsed line 1562\n",
      "Successfully parsed line 1563\n",
      "Successfully parsed line 1564\n",
      "Successfully parsed line 1565\n",
      "Successfully parsed line 1566\n",
      "Successfully parsed line 1567\n",
      "Successfully parsed line 1568\n",
      "Successfully parsed line 1569\n",
      "Successfully parsed line 1570\n",
      "Successfully parsed line 1571\n",
      "Successfully parsed line 1572\n",
      "Successfully parsed line 1573\n",
      "Successfully parsed line 1574\n",
      "Successfully parsed line 1575\n",
      "Successfully parsed line 1576\n",
      "Successfully parsed line 1577\n",
      "Successfully parsed line 1578\n",
      "Successfully parsed line 1579\n",
      "Successfully parsed line 1580\n",
      "Successfully parsed line 1581\n",
      "Successfully parsed line 1582\n",
      "Successfully parsed line 1583\n",
      "Successfully parsed line 1584\n",
      "Successfully parsed line 1585\n",
      "Successfully parsed line 1586\n",
      "Successfully parsed line 1587\n",
      "Successfully parsed line 1588\n",
      "Successfully parsed line 1589\n",
      "Successfully parsed line 1590\n",
      "Successfully parsed line 1591\n",
      "Successfully parsed line 1592\n",
      "Successfully parsed line 1593\n",
      "Successfully parsed line 1594\n",
      "Successfully parsed line 1595\n",
      "Successfully parsed line 1596\n",
      "Successfully parsed line 1597\n",
      "Successfully parsed line 1598\n",
      "Successfully parsed line 1599\n",
      "Successfully parsed line 1600\n",
      "Successfully parsed line 1601\n",
      "Successfully parsed line 1602\n",
      "Successfully parsed line 1603\n",
      "Successfully parsed line 1604\n",
      "Successfully parsed line 1605\n",
      "Successfully parsed line 1606\n",
      "Successfully parsed line 1607\n",
      "Successfully parsed line 1608\n",
      "Successfully parsed line 1609\n",
      "Successfully parsed line 1610\n",
      "Successfully parsed line 1611\n",
      "Successfully parsed line 1612\n",
      "Successfully parsed line 1613\n",
      "Successfully parsed line 1614\n",
      "Successfully parsed line 1615\n",
      "Successfully parsed line 1616\n",
      "Successfully parsed line 1617\n",
      "Successfully parsed line 1618\n",
      "Successfully parsed line 1619\n",
      "Successfully parsed line 1620\n",
      "Successfully parsed line 1621\n",
      "Successfully parsed line 1622\n",
      "Successfully parsed line 1623\n",
      "Successfully parsed line 1624\n",
      "Successfully parsed line 1625\n",
      "Successfully parsed line 1626\n",
      "Successfully parsed line 1627\n",
      "Successfully parsed line 1628\n",
      "Successfully parsed line 1629\n",
      "Successfully parsed line 1630\n",
      "Successfully parsed line 1631\n",
      "Successfully parsed line 1632\n",
      "Successfully parsed line 1633\n",
      "Successfully parsed line 1634\n",
      "Successfully parsed line 1635\n",
      "Successfully parsed line 1636\n",
      "Successfully parsed line 1637\n",
      "Successfully parsed line 1638\n",
      "Successfully parsed line 1639\n",
      "Successfully parsed line 1640\n",
      "Successfully parsed line 1641\n",
      "Successfully parsed line 1642\n",
      "Successfully parsed line 1643\n",
      "Successfully parsed line 1644\n",
      "Successfully parsed line 1645\n",
      "Successfully parsed line 1646\n",
      "Successfully parsed line 1647\n",
      "Successfully parsed line 1648\n",
      "Successfully parsed line 1649\n",
      "Successfully parsed line 1650\n",
      "Successfully parsed line 1651\n",
      "Successfully parsed line 1652\n",
      "Successfully parsed line 1653\n",
      "Successfully parsed line 1654\n",
      "Successfully parsed line 1655\n",
      "Successfully parsed line 1656\n",
      "Successfully parsed line 1657\n",
      "Successfully parsed line 1658\n",
      "Successfully parsed line 1659\n",
      "Successfully parsed line 1660\n",
      "Successfully parsed line 1661\n",
      "Successfully parsed line 1662\n",
      "Successfully parsed line 1663\n",
      "Successfully parsed line 1664\n",
      "Successfully parsed line 1665\n",
      "Successfully parsed line 1666\n",
      "Successfully parsed line 1667\n",
      "Successfully parsed line 1668\n",
      "Successfully parsed line 1669\n",
      "Successfully parsed line 1670\n",
      "Successfully parsed line 1671\n",
      "Successfully parsed line 1672\n",
      "Successfully parsed line 1673\n",
      "Successfully parsed line 1674\n",
      "Successfully parsed line 1675\n",
      "Successfully parsed line 1676\n",
      "Successfully parsed line 1677\n",
      "Successfully parsed line 1678\n",
      "Successfully parsed line 1679\n",
      "Successfully parsed line 1680\n",
      "Successfully parsed line 1681\n",
      "Successfully parsed line 1682\n",
      "Successfully parsed line 1683\n",
      "Successfully parsed line 1684\n",
      "Successfully parsed line 1685\n",
      "Successfully parsed line 1686\n",
      "Successfully parsed line 1687\n",
      "Successfully parsed line 1688\n",
      "Successfully parsed line 1689\n",
      "Successfully parsed line 1690\n",
      "Successfully parsed line 1691\n",
      "Successfully parsed line 1692\n",
      "Successfully parsed line 1693\n",
      "Successfully parsed line 1694\n",
      "Successfully parsed line 1695\n",
      "Successfully parsed line 1696\n",
      "Successfully parsed line 1697\n",
      "Successfully parsed line 1698\n",
      "Successfully parsed line 1699\n",
      "Successfully parsed line 1700\n",
      "Successfully parsed line 1701\n",
      "Successfully parsed line 1702\n",
      "Successfully parsed line 1703\n",
      "Successfully parsed line 1704\n",
      "Successfully parsed line 1705\n",
      "Successfully parsed line 1706\n",
      "Successfully parsed line 1707\n",
      "Successfully parsed line 1708\n",
      "Successfully parsed line 1709\n",
      "Successfully parsed line 1710\n",
      "Successfully parsed line 1711\n",
      "Successfully parsed line 1712\n",
      "Successfully parsed line 1713\n",
      "Successfully parsed line 1714\n",
      "Successfully parsed line 1715\n",
      "Successfully parsed line 1716\n",
      "Successfully parsed line 1717\n",
      "Successfully parsed line 1718\n",
      "Successfully parsed line 1719\n",
      "Successfully parsed line 1720\n",
      "Successfully parsed line 1721\n",
      "Successfully parsed line 1722\n",
      "Successfully parsed line 1723\n",
      "Successfully parsed line 1724\n",
      "Successfully parsed line 1725\n",
      "Successfully parsed line 1726\n",
      "Successfully parsed line 1727\n",
      "Successfully parsed line 1728\n",
      "Successfully parsed line 1729\n",
      "Successfully parsed line 1730\n",
      "Successfully parsed line 1731\n",
      "Successfully parsed line 1732\n",
      "Successfully parsed line 1733\n",
      "Successfully parsed line 1734\n",
      "Successfully parsed line 1735\n",
      "Successfully parsed line 1736\n",
      "Successfully parsed line 1737\n",
      "Successfully parsed line 1738\n",
      "Successfully parsed line 1739\n",
      "Successfully parsed line 1740\n",
      "Successfully parsed line 1741\n",
      "Successfully parsed line 1742\n",
      "Successfully parsed line 1743\n",
      "Successfully parsed line 1744\n",
      "Successfully parsed line 1745\n",
      "Successfully parsed line 1746\n",
      "Successfully parsed line 1747\n",
      "Successfully parsed line 1748\n",
      "Successfully parsed line 1749\n",
      "Successfully parsed line 1750\n",
      "Successfully parsed line 1751\n",
      "Successfully parsed line 1752\n",
      "Successfully parsed line 1753\n",
      "Successfully parsed line 1754\n",
      "Successfully parsed line 1755\n",
      "Successfully parsed line 1756\n",
      "Successfully parsed line 1757\n",
      "Successfully parsed line 1758\n",
      "Successfully parsed line 1759\n",
      "Successfully parsed line 1760\n",
      "Successfully parsed line 1761\n",
      "Successfully parsed line 1762\n",
      "Successfully parsed line 1763\n",
      "Successfully parsed line 1764\n",
      "Successfully parsed line 1765\n",
      "Successfully parsed line 1766\n",
      "Successfully parsed line 1767\n",
      "Successfully parsed line 1768\n",
      "Successfully parsed line 1769\n",
      "Successfully parsed line 1770\n",
      "Successfully parsed line 1771\n",
      "Successfully parsed line 1772\n",
      "Successfully parsed line 1773\n",
      "Successfully parsed line 1774\n",
      "Successfully parsed line 1775\n",
      "Successfully parsed line 1776\n",
      "Total parsed entries: 1776\n"
     ]
    }
   ],
   "source": [
    "# Load data from JSONL file\n",
    "try:\n",
    "    questions, answers = load_data_from_jsonl(TRAINING_DATA_PATH)\n",
    "    print(f\"Total parsed entries: {len(questions)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load data: {e}\")\n",
    "    questions, answers = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and evaluation sets\n",
    "train_size = int(0.9 * len(questions))\n",
    "train_questions = questions[:train_size]\n",
    "train_answers = answers[:train_size]\n",
    "eval_questions = questions[train_size:]\n",
    "eval_answers = answers[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example training record:\n",
      "\n",
      "###According to Simpler Trading, What asset classes is John Carter's Sandbox Strategy traded in?@@@John Carter's Sandbox Strategy is traded in Options<eos>\n",
      "Example evaluation record:\n",
      "\n",
      "###According to Simpler Trading, What functionalities does Raghee Horner’s HPMR Indicator offer?@@@The Raghee Horner’s HPMR Indicator - The Hourly Price Movement Range (HPMR) indicator is designed to forecast volatility-based support and resistance in a 24-hour timeframe. \n",
      "\n",
      "This indicator allows Raghee to measure time and volatility during special economic events or highly volatile hours in the day, such as the opening bell, midday, and the close. \n",
      "\n",
      "The HPMR indicator gives Raghee a next-level view of market direction.<eos>\n"
     ]
    }
   ],
   "source": [
    "# Prepare the fine-tuning training dataset\n",
    "if train_questions and train_answers:\n",
    "    combined_texts_train = [combine_texts(question, answer) for question, answer in zip(train_questions, train_answers)]\n",
    "    combined_texts_eval = [combine_texts(question, answer) for question, answer in zip(eval_questions, eval_answers)]\n",
    "\n",
    "    # Create the fine-tuning datasets\n",
    "    train_dataset = Dataset.from_dict({\"text\": [ct[\"text\"] for ct in combined_texts_train]})\n",
    "    eval_dataset = Dataset.from_dict({\"text\": [ct[\"text\"] for ct in combined_texts_eval]})\n",
    "\n",
    "    # Display example training record\n",
    "    if len(train_dataset) > 0:\n",
    "        print(\"Example training record:\\n\")\n",
    "        print(train_dataset[0]['text'])\n",
    "    else:\n",
    "        print(\"The fine-tuning training dataset is empty.\")\n",
    "    \n",
    "    if len(eval_dataset) > 0:\n",
    "        print(\"Example evaluation record:\\n\")\n",
    "        print(eval_dataset[0]['text'])\n",
    "    else:\n",
    "        print(\"The fine-tuning evaluation dataset is empty.\")\n",
    "else:\n",
    "    print(\"Failed to create the fine-tuning datasets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------Training Data Token Counts----------------------\n",
      "Measure       Question      Answer        Combined      \n",
      "Maximums      33            475           499           \n",
      "Max Seq Len                               509           \n",
      "\n",
      "Set max_seq_length in FastLanguageModel to 509 to handle the maximum number of tokens required by the input training data (Combined Maximum + Buffer).\n"
     ]
    }
   ],
   "source": [
    "max_qna = 0\n",
    "max_q = 0\n",
    "max_a = 0\n",
    "for question, answer in zip(questions, answers):\n",
    "    q_tokens = tokenizer.encode_plus(question, add_special_tokens=False, max_length=None)[\"input_ids\"]\n",
    "    a_tokens = tokenizer.encode_plus(answer, add_special_tokens=False, max_length=None)[\"input_ids\"]\n",
    "    qna_tokens = tokenizer.encode_plus(combine_texts(question, answer)[\"text\"], add_special_tokens=False, max_length=None)[\"input_ids\"]\n",
    "\n",
    "    max_q = max(max_q, len(q_tokens))\n",
    "    max_a = max(max_a, len(a_tokens))\n",
    "    max_qna = max(max_qna, len(qna_tokens))\n",
    "\n",
    "buffer = 10\n",
    "max_seq_length = max_qna + buffer\n",
    "\n",
    "table_title = \"Training Data Token Counts\"\n",
    "print(f\"\\n{table_title:-^70}\")\n",
    "print(f\"{'Measure':<14}{'Question':<14}{'Answer':<14}{'Combined':<14}\")\n",
    "\n",
    "print(f\"{'Maximums':<14}{max_q:<14}{max_a:<14}{max_qna:<14}\")\n",
    "print(f\"{'Max Seq Len':<14}{'':<14}{'':<14}{max_seq_length:<14}\\n\")\n",
    "\n",
    "print(f\"Set max_seq_length in FastLanguageModel to {max_seq_length} to handle the maximum number of tokens required by the input training data (Combined Maximum + Buffer).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: If you want to finetune Gemma 2, install flash-attn to make it faster!\n",
      "To install flash-attn, do the below:\n",
      "\n",
      "pip install --no-deps --upgrade \"flash-attn>=2.6.3\"\n",
      "==((====))==  Unsloth 2024.8: Fast Gemma2 patching. Transformers = 4.43.3.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.668 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.3.1. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    }
   ],
   "source": [
    "dtype = None \n",
    "load_in_4bit = True\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(    \n",
    "    model_name = MODEL_NAME,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # add a Hugging Face access token if using a private or gated model\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Already have LoRA adapters! We shall skip this step.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Casting embed_tokens to float32\n",
      "Unsloth: Casting lm_head to float32\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 128, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "\n",
    "                      \"embed_tokens\", \"lm_head\",], # Add for continual pretraining\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = True,   # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce RTX 3090. Max memory = 23.668 GB.\n",
      "16.17 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "#@title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clear memory if needed.. if not needed.. no worries.. skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA memory cleared.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "def clear_cuda_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(\"CUDA memory cleared.\")\n",
    "\n",
    "# Call the function to clear memory\n",
    "clear_cuda_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging configuration to wandb\n",
    "config = {\n",
    "    \"learning_rate\": 2e-5,    \n",
    "    \"batch_size\": 2,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"num_train_epochs\": 20,  # Increased to allow early stopping to take effect\n",
    "    \"warmup_steps\": 100,\n",
    "    \"max_seq_length\": max_seq_length,  # To be calculated later\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config.update(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dave/miniconda3/envs/unsloth_env/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=config['batch_size'],\n",
    "    gradient_accumulation_steps=config['gradient_accumulation_steps'],\n",
    "    warmup_steps=config['warmup_steps'],\n",
    "    num_train_epochs=config['num_train_epochs'],\n",
    "    learning_rate=config['learning_rate'],\n",
    "    fp16=not torch.cuda.is_bf16_supported(),\n",
    "    bf16=torch.cuda.is_bf16_supported(),\n",
    "    logging_steps=5,\n",
    "    optim=\"adamw_8bit\",\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    seed=3407,\n",
    "    output_dir=\"outputs\",\n",
    "    report_to=\"wandb\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=3,  # Limit to 3 checkpoints\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",  # Use evaluation loss to determine the best model\n",
    "    greater_is_better=False,  # Lower loss is better\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup callbacks for WANDB logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WandbCallback(TrainerCallback):\n",
    "    def on_log(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        if state.log_history:\n",
    "            wandb.log(state.log_history[-1])\n",
    "\n",
    "    def on_train_begin(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        wandb.init(project=\"your_project_name\", config=args)\n",
    "\n",
    "    def on_train_end(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        wandb.finish()\n",
    "\n",
    "    def on_evaluate(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        if state.log_history:\n",
    "            wandb.log(state.log_history[-1])\n",
    "\n",
    "    def on_save(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        wandb.log({\"global_step\": state.global_step, \"saving_checkpoint\": True})\n",
    "\n",
    "    def on_epoch_end(self, args, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        if state.log_history:\n",
    "            wandb.log(state.log_history[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce72f821b9224ac08c0cf097db9be43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/1598 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c28f6a55d094a2d81b61d2e04bbf0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/178 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize trainer with the enhanced WandbCallback\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,  # Add evaluation dataset for monitoring\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dataset_num_proc=2,\n",
    "    packing=False,\n",
    "    args=training_args,\n",
    "    callbacks=[WandbCallback(), EarlyStoppingCallback(early_stopping_patience=4)],  # Add early stopping callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,598 | Num Epochs = 20\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 3,980\n",
      " \"-____-\"     Number of trainable parameters = 1,345,781,760\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:yzcqw95v) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6788e2b3655449dfa6c2e2e2ffd05dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dazzling-salad-13</strong> at: <a href='https://wandb.ai/davidbzyk/Simpler/runs/yzcqw95v' target=\"_blank\">https://wandb.ai/davidbzyk/Simpler/runs/yzcqw95v</a><br/> View project at: <a href='https://wandb.ai/davidbzyk/Simpler' target=\"_blank\">https://wandb.ai/davidbzyk/Simpler</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240804_130037-yzcqw95v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:yzcqw95v). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ab732f98dd49798449af52617706a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112175899971691, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/dave/Desktop/simpler/simpler-prod-qa/Step-2-Training/step2b-finetune/wandb/run-20240804_130249-m97lalo7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/davidbzyk/your_project_name/runs/m97lalo7' target=\"_blank\">lilac-water-5</a></strong> to <a href='https://wandb.ai/davidbzyk/your_project_name' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/davidbzyk/your_project_name' target=\"_blank\">https://wandb.ai/davidbzyk/your_project_name</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/davidbzyk/your_project_name/runs/m97lalo7' target=\"_blank\">https://wandb.ai/davidbzyk/your_project_name/runs/m97lalo7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a42e91b3a6df4545ae5d5b2494b67424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3980 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.6367, 'grad_norm': 65.17147064208984, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.03}\n",
      "{'loss': 4.1585, 'grad_norm': 47.89892578125, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.05}\n",
      "{'loss': 3.0793, 'grad_norm': 40.855445861816406, 'learning_rate': 3e-06, 'epoch': 0.08}\n",
      "{'loss': 2.6244, 'grad_norm': 27.010238647460938, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.1}\n",
      "{'loss': 1.8499, 'grad_norm': 26.952211380004883, 'learning_rate': 5e-06, 'epoch': 0.13}\n",
      "{'loss': 1.2679, 'grad_norm': 20.45762062072754, 'learning_rate': 6e-06, 'epoch': 0.15}\n",
      "{'loss': 0.8423, 'grad_norm': 13.93791675567627, 'learning_rate': 7e-06, 'epoch': 0.18}\n",
      "{'loss': 0.613, 'grad_norm': 7.822998523712158, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.2}\n",
      "{'loss': 0.6006, 'grad_norm': 13.41559886932373, 'learning_rate': 9e-06, 'epoch': 0.23}\n",
      "{'loss': 0.498, 'grad_norm': 17.745641708374023, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 0.5708, 'grad_norm': 13.377673149108887, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.28}\n",
      "{'loss': 0.4264, 'grad_norm': 7.9275102615356445, 'learning_rate': 1.2e-05, 'epoch': 0.3}\n",
      "{'loss': 0.4971, 'grad_norm': 13.093599319458008, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.33}\n",
      "{'loss': 0.4124, 'grad_norm': 11.038962364196777, 'learning_rate': 1.4e-05, 'epoch': 0.35}\n",
      "{'loss': 0.3481, 'grad_norm': 8.42613410949707, 'learning_rate': 1.5000000000000002e-05, 'epoch': 0.38}\n",
      "{'loss': 0.3269, 'grad_norm': 8.050217628479004, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.4}\n",
      "{'loss': 0.3403, 'grad_norm': 7.0033745765686035, 'learning_rate': 1.7e-05, 'epoch': 0.43}\n",
      "{'loss': 0.3825, 'grad_norm': 12.046756744384766, 'learning_rate': 1.8e-05, 'epoch': 0.45}\n",
      "{'loss': 0.368, 'grad_norm': 9.971632957458496, 'learning_rate': 1.9e-05, 'epoch': 0.48}\n",
      "{'loss': 0.4013, 'grad_norm': 8.013272285461426, 'learning_rate': 2e-05, 'epoch': 0.5}\n",
      "{'loss': 0.3362, 'grad_norm': 6.2915520668029785, 'learning_rate': 1.9974226804123712e-05, 'epoch': 0.53}\n",
      "{'loss': 0.2854, 'grad_norm': 8.740704536437988, 'learning_rate': 1.9948453608247426e-05, 'epoch': 0.55}\n",
      "{'loss': 0.3525, 'grad_norm': 10.666388511657715, 'learning_rate': 1.9922680412371136e-05, 'epoch': 0.58}\n",
      "{'loss': 0.3126, 'grad_norm': 8.439408302307129, 'learning_rate': 1.9896907216494847e-05, 'epoch': 0.6}\n",
      "{'loss': 0.286, 'grad_norm': 11.510601997375488, 'learning_rate': 1.9871134020618557e-05, 'epoch': 0.63}\n",
      "{'loss': 0.3504, 'grad_norm': 10.061929702758789, 'learning_rate': 1.984536082474227e-05, 'epoch': 0.65}\n",
      "{'loss': 0.3472, 'grad_norm': 8.646246910095215, 'learning_rate': 1.981958762886598e-05, 'epoch': 0.68}\n",
      "{'loss': 0.2951, 'grad_norm': 8.043828964233398, 'learning_rate': 1.9793814432989692e-05, 'epoch': 0.7}\n",
      "{'loss': 0.2349, 'grad_norm': 5.220456600189209, 'learning_rate': 1.9768041237113406e-05, 'epoch': 0.73}\n",
      "{'loss': 0.3004, 'grad_norm': 8.257728576660156, 'learning_rate': 1.9742268041237116e-05, 'epoch': 0.75}\n",
      "{'loss': 0.2834, 'grad_norm': 7.224959373474121, 'learning_rate': 1.9716494845360827e-05, 'epoch': 0.78}\n",
      "{'loss': 0.2425, 'grad_norm': 8.553472518920898, 'learning_rate': 1.969072164948454e-05, 'epoch': 0.8}\n",
      "{'loss': 0.2726, 'grad_norm': 8.110822677612305, 'learning_rate': 1.9664948453608247e-05, 'epoch': 0.83}\n",
      "{'loss': 0.2717, 'grad_norm': 4.751966953277588, 'learning_rate': 1.9639175257731958e-05, 'epoch': 0.85}\n",
      "{'loss': 0.2411, 'grad_norm': 6.287155628204346, 'learning_rate': 1.9613402061855672e-05, 'epoch': 0.88}\n",
      "{'loss': 0.2046, 'grad_norm': 8.457144737243652, 'learning_rate': 1.9587628865979382e-05, 'epoch': 0.9}\n",
      "{'loss': 0.2138, 'grad_norm': 4.2817792892456055, 'learning_rate': 1.9561855670103093e-05, 'epoch': 0.93}\n",
      "{'loss': 0.2351, 'grad_norm': 4.899578094482422, 'learning_rate': 1.9536082474226806e-05, 'epoch': 0.95}\n",
      "{'loss': 0.2438, 'grad_norm': 4.775477886199951, 'learning_rate': 1.9510309278350517e-05, 'epoch': 0.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a7606a4ad742b79e199b718fe274eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.383622169494629, 'eval_runtime': 3.0496, 'eval_samples_per_second': 58.368, 'eval_steps_per_second': 7.542, 'epoch': 1.0}\n",
      "{'loss': 0.2434, 'grad_norm': 3.4169299602508545, 'learning_rate': 1.9484536082474227e-05, 'epoch': 1.0}\n",
      "{'loss': 0.216, 'grad_norm': 6.130731582641602, 'learning_rate': 1.945876288659794e-05, 'epoch': 1.03}\n",
      "{'loss': 0.1959, 'grad_norm': 6.7535552978515625, 'learning_rate': 1.943298969072165e-05, 'epoch': 1.05}\n",
      "{'loss': 0.2002, 'grad_norm': 4.5460686683654785, 'learning_rate': 1.9407216494845362e-05, 'epoch': 1.08}\n",
      "{'loss': 0.1855, 'grad_norm': 4.6880784034729, 'learning_rate': 1.9381443298969072e-05, 'epoch': 1.1}\n",
      "{'loss': 0.1916, 'grad_norm': 4.584428787231445, 'learning_rate': 1.9355670103092786e-05, 'epoch': 1.13}\n",
      "{'loss': 0.209, 'grad_norm': 3.383728265762329, 'learning_rate': 1.9329896907216497e-05, 'epoch': 1.15}\n",
      "{'loss': 0.2333, 'grad_norm': 5.4529523849487305, 'learning_rate': 1.9304123711340207e-05, 'epoch': 1.18}\n",
      "{'loss': 0.1984, 'grad_norm': 3.6788432598114014, 'learning_rate': 1.927835051546392e-05, 'epoch': 1.2}\n",
      "{'loss': 0.2368, 'grad_norm': 4.544931888580322, 'learning_rate': 1.925257731958763e-05, 'epoch': 1.23}\n",
      "{'loss': 0.2388, 'grad_norm': 3.3454151153564453, 'learning_rate': 1.9226804123711342e-05, 'epoch': 1.25}\n",
      "{'loss': 0.1987, 'grad_norm': 3.8614377975463867, 'learning_rate': 1.9201030927835052e-05, 'epoch': 1.28}\n",
      "{'loss': 0.1676, 'grad_norm': 10.858909606933594, 'learning_rate': 1.9175257731958766e-05, 'epoch': 1.3}\n",
      "{'loss': 0.1899, 'grad_norm': 3.451864004135132, 'learning_rate': 1.9149484536082476e-05, 'epoch': 1.33}\n",
      "{'loss': 0.1835, 'grad_norm': 3.9612464904785156, 'learning_rate': 1.9123711340206187e-05, 'epoch': 1.35}\n",
      "{'loss': 0.1538, 'grad_norm': 5.506350040435791, 'learning_rate': 1.90979381443299e-05, 'epoch': 1.38}\n",
      "{'loss': 0.1779, 'grad_norm': 4.123157501220703, 'learning_rate': 1.907216494845361e-05, 'epoch': 1.4}\n",
      "{'loss': 0.213, 'grad_norm': 5.3406291007995605, 'learning_rate': 1.904639175257732e-05, 'epoch': 1.43}\n",
      "{'loss': 0.1831, 'grad_norm': 2.8656632900238037, 'learning_rate': 1.9020618556701032e-05, 'epoch': 1.45}\n",
      "{'loss': 0.1541, 'grad_norm': 2.0501444339752197, 'learning_rate': 1.8994845360824742e-05, 'epoch': 1.48}\n",
      "{'loss': 0.1723, 'grad_norm': 3.226814031600952, 'learning_rate': 1.8969072164948453e-05, 'epoch': 1.5}\n",
      "{'loss': 0.1941, 'grad_norm': 3.7783188819885254, 'learning_rate': 1.8943298969072167e-05, 'epoch': 1.53}\n",
      "{'loss': 0.2055, 'grad_norm': 8.483177185058594, 'learning_rate': 1.8917525773195877e-05, 'epoch': 1.55}\n",
      "{'loss': 0.1945, 'grad_norm': 3.7559006214141846, 'learning_rate': 1.8891752577319588e-05, 'epoch': 1.58}\n",
      "{'loss': 0.1888, 'grad_norm': 4.1378583908081055, 'learning_rate': 1.88659793814433e-05, 'epoch': 1.6}\n",
      "{'loss': 0.1443, 'grad_norm': 2.7957425117492676, 'learning_rate': 1.8840206185567012e-05, 'epoch': 1.63}\n",
      "{'loss': 0.2442, 'grad_norm': 3.838992118835449, 'learning_rate': 1.8814432989690722e-05, 'epoch': 1.65}\n",
      "{'loss': 0.1795, 'grad_norm': 2.7144505977630615, 'learning_rate': 1.8788659793814433e-05, 'epoch': 1.68}\n",
      "{'loss': 0.2087, 'grad_norm': 1.8319438695907593, 'learning_rate': 1.8762886597938147e-05, 'epoch': 1.7}\n",
      "{'loss': 0.2042, 'grad_norm': 2.204071283340454, 'learning_rate': 1.8737113402061857e-05, 'epoch': 1.73}\n",
      "{'loss': 0.2029, 'grad_norm': 2.4764113426208496, 'learning_rate': 1.8711340206185567e-05, 'epoch': 1.75}\n",
      "{'loss': 0.1821, 'grad_norm': 7.229604721069336, 'learning_rate': 1.868556701030928e-05, 'epoch': 1.78}\n",
      "{'loss': 0.2228, 'grad_norm': 4.453837871551514, 'learning_rate': 1.865979381443299e-05, 'epoch': 1.8}\n",
      "{'loss': 0.1878, 'grad_norm': 3.9711477756500244, 'learning_rate': 1.8634020618556702e-05, 'epoch': 1.83}\n",
      "{'loss': 0.1927, 'grad_norm': 3.4242682456970215, 'learning_rate': 1.8608247422680416e-05, 'epoch': 1.85}\n",
      "{'loss': 0.1972, 'grad_norm': 3.1072041988372803, 'learning_rate': 1.8582474226804126e-05, 'epoch': 1.88}\n",
      "{'loss': 0.1683, 'grad_norm': 2.279839277267456, 'learning_rate': 1.8556701030927837e-05, 'epoch': 1.9}\n",
      "{'loss': 0.1844, 'grad_norm': 1.781416893005371, 'learning_rate': 1.8530927835051547e-05, 'epoch': 1.93}\n",
      "{'loss': 0.1928, 'grad_norm': 4.243430137634277, 'learning_rate': 1.850515463917526e-05, 'epoch': 1.95}\n",
      "{'loss': 0.1982, 'grad_norm': 2.7097127437591553, 'learning_rate': 1.847938144329897e-05, 'epoch': 1.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca9c739431e48a5803bb8341204a459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7207645177841187, 'eval_runtime': 3.4883, 'eval_samples_per_second': 51.028, 'eval_steps_per_second': 6.593, 'epoch': 2.0}\n",
      "{'loss': 0.1692, 'grad_norm': 2.5331082344055176, 'learning_rate': 1.8453608247422682e-05, 'epoch': 2.0}\n",
      "{'loss': 0.1656, 'grad_norm': 3.2688934803009033, 'learning_rate': 1.8427835051546392e-05, 'epoch': 2.03}\n",
      "{'loss': 0.1575, 'grad_norm': 2.992992401123047, 'learning_rate': 1.8402061855670103e-05, 'epoch': 2.05}\n",
      "{'loss': 0.1863, 'grad_norm': 2.554945230484009, 'learning_rate': 1.8376288659793817e-05, 'epoch': 2.08}\n",
      "{'loss': 0.1822, 'grad_norm': 1.718431830406189, 'learning_rate': 1.8350515463917527e-05, 'epoch': 2.1}\n",
      "{'loss': 0.155, 'grad_norm': 2.428297281265259, 'learning_rate': 1.8324742268041237e-05, 'epoch': 2.13}\n",
      "{'loss': 0.138, 'grad_norm': 2.4470460414886475, 'learning_rate': 1.8298969072164948e-05, 'epoch': 2.15}\n",
      "{'loss': 0.1797, 'grad_norm': 2.008721351623535, 'learning_rate': 1.8273195876288662e-05, 'epoch': 2.18}\n",
      "{'loss': 0.1765, 'grad_norm': 2.522097587585449, 'learning_rate': 1.8247422680412372e-05, 'epoch': 2.2}\n",
      "{'loss': 0.1648, 'grad_norm': 3.146129846572876, 'learning_rate': 1.8221649484536083e-05, 'epoch': 2.23}\n",
      "{'loss': 0.1464, 'grad_norm': 1.1274302005767822, 'learning_rate': 1.8195876288659796e-05, 'epoch': 2.25}\n",
      "{'loss': 0.1347, 'grad_norm': 0.9703686237335205, 'learning_rate': 1.8170103092783507e-05, 'epoch': 2.28}\n",
      "{'loss': 0.1479, 'grad_norm': 1.808752179145813, 'learning_rate': 1.8144329896907217e-05, 'epoch': 2.3}\n",
      "{'loss': 0.1927, 'grad_norm': 4.8475775718688965, 'learning_rate': 1.8118556701030928e-05, 'epoch': 2.33}\n",
      "{'loss': 0.1917, 'grad_norm': 4.1359944343566895, 'learning_rate': 1.809278350515464e-05, 'epoch': 2.35}\n",
      "{'loss': 0.1546, 'grad_norm': 6.231958389282227, 'learning_rate': 1.8067010309278352e-05, 'epoch': 2.38}\n",
      "{'loss': 0.1529, 'grad_norm': 6.448459625244141, 'learning_rate': 1.8041237113402062e-05, 'epoch': 2.4}\n",
      "{'loss': 0.1471, 'grad_norm': 2.0840938091278076, 'learning_rate': 1.8015463917525776e-05, 'epoch': 2.43}\n",
      "{'loss': 0.1708, 'grad_norm': 2.6820297241210938, 'learning_rate': 1.7989690721649487e-05, 'epoch': 2.45}\n",
      "{'loss': 0.1649, 'grad_norm': 2.7706220149993896, 'learning_rate': 1.7963917525773197e-05, 'epoch': 2.48}\n",
      "{'loss': 0.2013, 'grad_norm': 5.892012596130371, 'learning_rate': 1.793814432989691e-05, 'epoch': 2.5}\n",
      "{'loss': 0.1815, 'grad_norm': 1.5287606716156006, 'learning_rate': 1.791237113402062e-05, 'epoch': 2.53}\n",
      "{'loss': 0.1907, 'grad_norm': 1.3661388158798218, 'learning_rate': 1.7886597938144332e-05, 'epoch': 2.55}\n",
      "{'loss': 0.1494, 'grad_norm': 1.96696937084198, 'learning_rate': 1.7860824742268042e-05, 'epoch': 2.58}\n",
      "{'loss': 0.178, 'grad_norm': 3.429095506668091, 'learning_rate': 1.7835051546391756e-05, 'epoch': 2.6}\n",
      "{'loss': 0.1594, 'grad_norm': 1.899369239807129, 'learning_rate': 1.7809278350515463e-05, 'epoch': 2.63}\n",
      "{'loss': 0.1159, 'grad_norm': 1.1290758848190308, 'learning_rate': 1.7783505154639177e-05, 'epoch': 2.65}\n",
      "{'loss': 0.1674, 'grad_norm': 1.2517622709274292, 'learning_rate': 1.7757731958762887e-05, 'epoch': 2.68}\n",
      "{'loss': 0.1773, 'grad_norm': 3.2615163326263428, 'learning_rate': 1.7731958762886598e-05, 'epoch': 2.7}\n",
      "{'loss': 0.1549, 'grad_norm': 2.757655143737793, 'learning_rate': 1.770618556701031e-05, 'epoch': 2.73}\n",
      "{'loss': 0.1453, 'grad_norm': 1.413610816001892, 'learning_rate': 1.7680412371134022e-05, 'epoch': 2.75}\n",
      "{'loss': 0.1548, 'grad_norm': 4.870026588439941, 'learning_rate': 1.7654639175257732e-05, 'epoch': 2.78}\n",
      "{'loss': 0.1732, 'grad_norm': 2.884850025177002, 'learning_rate': 1.7628865979381443e-05, 'epoch': 2.8}\n",
      "{'loss': 0.1921, 'grad_norm': 0.7264522910118103, 'learning_rate': 1.7603092783505157e-05, 'epoch': 2.83}\n",
      "{'loss': 0.1582, 'grad_norm': 2.671053886413574, 'learning_rate': 1.7577319587628867e-05, 'epoch': 2.85}\n",
      "{'loss': 0.1457, 'grad_norm': 2.286590337753296, 'learning_rate': 1.7551546391752578e-05, 'epoch': 2.88}\n",
      "{'loss': 0.1646, 'grad_norm': 3.0653162002563477, 'learning_rate': 1.752577319587629e-05, 'epoch': 2.9}\n",
      "{'loss': 0.1486, 'grad_norm': 6.193119049072266, 'learning_rate': 1.7500000000000002e-05, 'epoch': 2.93}\n",
      "{'loss': 0.1553, 'grad_norm': 3.824099540710449, 'learning_rate': 1.7474226804123712e-05, 'epoch': 2.95}\n",
      "{'loss': 0.1763, 'grad_norm': 2.3592686653137207, 'learning_rate': 1.7448453608247423e-05, 'epoch': 2.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3e0178f22548fb9a587cf16091ed74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9425874948501587, 'eval_runtime': 3.3503, 'eval_samples_per_second': 53.13, 'eval_steps_per_second': 6.865, 'epoch': 3.0}\n",
      "{'loss': 0.1465, 'grad_norm': 1.9999428987503052, 'learning_rate': 1.7422680412371137e-05, 'epoch': 3.0}\n",
      "{'loss': 0.1565, 'grad_norm': 3.188136577606201, 'learning_rate': 1.7396907216494847e-05, 'epoch': 3.03}\n",
      "{'loss': 0.1265, 'grad_norm': 2.0676491260528564, 'learning_rate': 1.7371134020618557e-05, 'epoch': 3.05}\n",
      "{'loss': 0.1295, 'grad_norm': 1.6413792371749878, 'learning_rate': 1.734536082474227e-05, 'epoch': 3.08}\n",
      "{'loss': 0.1632, 'grad_norm': 1.7946549654006958, 'learning_rate': 1.731958762886598e-05, 'epoch': 3.1}\n",
      "{'loss': 0.1488, 'grad_norm': 2.109586238861084, 'learning_rate': 1.7293814432989692e-05, 'epoch': 3.13}\n",
      "{'loss': 0.1318, 'grad_norm': 3.126887321472168, 'learning_rate': 1.7268041237113406e-05, 'epoch': 3.15}\n",
      "{'loss': 0.1423, 'grad_norm': 3.2133989334106445, 'learning_rate': 1.7242268041237116e-05, 'epoch': 3.18}\n",
      "{'loss': 0.1405, 'grad_norm': 2.0806686878204346, 'learning_rate': 1.7216494845360827e-05, 'epoch': 3.2}\n",
      "{'loss': 0.1518, 'grad_norm': 2.222916603088379, 'learning_rate': 1.7190721649484537e-05, 'epoch': 3.23}\n",
      "{'loss': 0.1722, 'grad_norm': 1.021553874015808, 'learning_rate': 1.7164948453608248e-05, 'epoch': 3.25}\n",
      "{'loss': 0.1729, 'grad_norm': 3.5869157314300537, 'learning_rate': 1.7139175257731958e-05, 'epoch': 3.28}\n",
      "{'loss': 0.1492, 'grad_norm': 2.2321386337280273, 'learning_rate': 1.7113402061855672e-05, 'epoch': 3.3}\n",
      "{'loss': 0.1598, 'grad_norm': 3.2024269104003906, 'learning_rate': 1.7087628865979382e-05, 'epoch': 3.33}\n",
      "{'loss': 0.1556, 'grad_norm': 3.5470175743103027, 'learning_rate': 1.7061855670103093e-05, 'epoch': 3.35}\n",
      "{'loss': 0.1234, 'grad_norm': 0.7768135070800781, 'learning_rate': 1.7036082474226807e-05, 'epoch': 3.38}\n",
      "{'loss': 0.1423, 'grad_norm': 1.3838889598846436, 'learning_rate': 1.7010309278350517e-05, 'epoch': 3.4}\n",
      "{'loss': 0.142, 'grad_norm': 0.5453858971595764, 'learning_rate': 1.6984536082474227e-05, 'epoch': 3.43}\n",
      "{'loss': 0.1446, 'grad_norm': 3.587592601776123, 'learning_rate': 1.6958762886597938e-05, 'epoch': 3.45}\n",
      "{'loss': 0.1478, 'grad_norm': 3.7676823139190674, 'learning_rate': 1.6932989690721652e-05, 'epoch': 3.48}\n",
      "{'loss': 0.1225, 'grad_norm': 0.8668301105499268, 'learning_rate': 1.6907216494845362e-05, 'epoch': 3.5}\n",
      "{'loss': 0.1552, 'grad_norm': 0.7033984661102295, 'learning_rate': 1.6881443298969073e-05, 'epoch': 3.53}\n",
      "{'loss': 0.1723, 'grad_norm': 6.4592390060424805, 'learning_rate': 1.6855670103092786e-05, 'epoch': 3.55}\n",
      "{'loss': 0.156, 'grad_norm': 6.25935697555542, 'learning_rate': 1.6829896907216497e-05, 'epoch': 3.58}\n",
      "{'loss': 0.1396, 'grad_norm': 0.7542030811309814, 'learning_rate': 1.6804123711340207e-05, 'epoch': 3.6}\n",
      "{'loss': 0.1392, 'grad_norm': 0.6200358271598816, 'learning_rate': 1.6778350515463918e-05, 'epoch': 3.63}\n",
      "{'loss': 0.1552, 'grad_norm': 1.0233819484710693, 'learning_rate': 1.675257731958763e-05, 'epoch': 3.65}\n",
      "{'loss': 0.1666, 'grad_norm': 2.5792179107666016, 'learning_rate': 1.6726804123711342e-05, 'epoch': 3.68}\n",
      "{'loss': 0.1457, 'grad_norm': 0.7205788493156433, 'learning_rate': 1.6701030927835052e-05, 'epoch': 3.7}\n",
      "{'loss': 0.1811, 'grad_norm': 3.109652519226074, 'learning_rate': 1.6675257731958766e-05, 'epoch': 3.73}\n",
      "{'loss': 0.1483, 'grad_norm': 3.2022063732147217, 'learning_rate': 1.6649484536082477e-05, 'epoch': 3.75}\n",
      "{'loss': 0.1523, 'grad_norm': 1.2589706182479858, 'learning_rate': 1.6623711340206187e-05, 'epoch': 3.78}\n",
      "{'loss': 0.1885, 'grad_norm': 2.8727304935455322, 'learning_rate': 1.65979381443299e-05, 'epoch': 3.8}\n",
      "{'loss': 0.1769, 'grad_norm': 1.370055079460144, 'learning_rate': 1.657216494845361e-05, 'epoch': 3.83}\n",
      "{'loss': 0.1488, 'grad_norm': 2.9118576049804688, 'learning_rate': 1.654639175257732e-05, 'epoch': 3.85}\n",
      "{'loss': 0.1626, 'grad_norm': 1.36506187915802, 'learning_rate': 1.6520618556701032e-05, 'epoch': 3.88}\n",
      "{'loss': 0.1651, 'grad_norm': 2.2478818893432617, 'learning_rate': 1.6494845360824743e-05, 'epoch': 3.9}\n",
      "{'loss': 0.1518, 'grad_norm': 5.281735897064209, 'learning_rate': 1.6469072164948453e-05, 'epoch': 3.93}\n",
      "{'loss': 0.1307, 'grad_norm': 0.6313665509223938, 'learning_rate': 1.6443298969072167e-05, 'epoch': 3.95}\n",
      "{'loss': 0.1469, 'grad_norm': 0.7328047752380371, 'learning_rate': 1.6417525773195877e-05, 'epoch': 3.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b39f15414824d579c4eabee23610ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1255507469177246, 'eval_runtime': 3.4799, 'eval_samples_per_second': 51.152, 'eval_steps_per_second': 6.609, 'epoch': 4.0}\n",
      "{'loss': 0.1408, 'grad_norm': 0.6535236835479736, 'learning_rate': 1.6391752577319588e-05, 'epoch': 4.01}\n",
      "{'loss': 0.1584, 'grad_norm': 4.755343437194824, 'learning_rate': 1.6365979381443298e-05, 'epoch': 4.03}\n",
      "{'loss': 0.1324, 'grad_norm': 1.3328018188476562, 'learning_rate': 1.6340206185567012e-05, 'epoch': 4.06}\n",
      "{'loss': 0.1712, 'grad_norm': 0.5289347171783447, 'learning_rate': 1.6314432989690722e-05, 'epoch': 4.08}\n",
      "{'loss': 0.147, 'grad_norm': 1.132416844367981, 'learning_rate': 1.6288659793814433e-05, 'epoch': 4.11}\n",
      "{'loss': 0.1474, 'grad_norm': 1.321629285812378, 'learning_rate': 1.6262886597938147e-05, 'epoch': 4.13}\n",
      "{'loss': 0.1362, 'grad_norm': 1.2519906759262085, 'learning_rate': 1.6237113402061857e-05, 'epoch': 4.16}\n",
      "{'loss': 0.1418, 'grad_norm': 0.7034764289855957, 'learning_rate': 1.6211340206185568e-05, 'epoch': 4.18}\n",
      "{'loss': 0.1298, 'grad_norm': 2.146009683609009, 'learning_rate': 1.618556701030928e-05, 'epoch': 4.21}\n",
      "{'loss': 0.1558, 'grad_norm': 1.1656641960144043, 'learning_rate': 1.6159793814432992e-05, 'epoch': 4.23}\n",
      "{'loss': 0.1366, 'grad_norm': 0.5535339713096619, 'learning_rate': 1.6134020618556702e-05, 'epoch': 4.26}\n",
      "{'loss': 0.1404, 'grad_norm': 0.8471068739891052, 'learning_rate': 1.6108247422680413e-05, 'epoch': 4.28}\n",
      "{'loss': 0.1275, 'grad_norm': 0.45277494192123413, 'learning_rate': 1.6082474226804127e-05, 'epoch': 4.31}\n",
      "{'loss': 0.1543, 'grad_norm': 0.503703236579895, 'learning_rate': 1.6056701030927837e-05, 'epoch': 4.33}\n",
      "{'loss': 0.1488, 'grad_norm': 0.6556762456893921, 'learning_rate': 1.6030927835051547e-05, 'epoch': 4.36}\n",
      "{'loss': 0.1466, 'grad_norm': 3.7492034435272217, 'learning_rate': 1.600515463917526e-05, 'epoch': 4.38}\n",
      "{'loss': 0.1428, 'grad_norm': 0.6687923073768616, 'learning_rate': 1.597938144329897e-05, 'epoch': 4.41}\n",
      "{'loss': 0.1833, 'grad_norm': 5.680636882781982, 'learning_rate': 1.5953608247422682e-05, 'epoch': 4.43}\n",
      "{'loss': 0.1331, 'grad_norm': 1.2263317108154297, 'learning_rate': 1.5927835051546393e-05, 'epoch': 4.46}\n",
      "{'loss': 0.1523, 'grad_norm': 1.1082574129104614, 'learning_rate': 1.5902061855670103e-05, 'epoch': 4.48}\n",
      "{'loss': 0.1244, 'grad_norm': 3.2542152404785156, 'learning_rate': 1.5876288659793813e-05, 'epoch': 4.51}\n",
      "{'loss': 0.1566, 'grad_norm': 0.8667674660682678, 'learning_rate': 1.5850515463917527e-05, 'epoch': 4.53}\n",
      "{'loss': 0.1258, 'grad_norm': 0.48142218589782715, 'learning_rate': 1.5824742268041238e-05, 'epoch': 4.56}\n",
      "{'loss': 0.1194, 'grad_norm': 0.41691550612449646, 'learning_rate': 1.5798969072164948e-05, 'epoch': 4.58}\n",
      "{'loss': 0.1461, 'grad_norm': 2.143441677093506, 'learning_rate': 1.5773195876288662e-05, 'epoch': 4.61}\n",
      "{'loss': 0.1517, 'grad_norm': 2.1709346771240234, 'learning_rate': 1.5747422680412372e-05, 'epoch': 4.63}\n",
      "{'loss': 0.1589, 'grad_norm': 4.2565460205078125, 'learning_rate': 1.5721649484536083e-05, 'epoch': 4.66}\n",
      "{'loss': 0.1048, 'grad_norm': 0.6668751835823059, 'learning_rate': 1.5695876288659793e-05, 'epoch': 4.68}\n",
      "{'loss': 0.1311, 'grad_norm': 3.56706166267395, 'learning_rate': 1.5670103092783507e-05, 'epoch': 4.71}\n",
      "{'loss': 0.1332, 'grad_norm': 1.0074411630630493, 'learning_rate': 1.5644329896907217e-05, 'epoch': 4.73}\n",
      "{'loss': 0.131, 'grad_norm': 1.9095728397369385, 'learning_rate': 1.5618556701030928e-05, 'epoch': 4.76}\n",
      "{'loss': 0.1383, 'grad_norm': 1.0518503189086914, 'learning_rate': 1.5592783505154642e-05, 'epoch': 4.78}\n",
      "{'loss': 0.1692, 'grad_norm': 0.44770461320877075, 'learning_rate': 1.5567010309278352e-05, 'epoch': 4.81}\n",
      "{'loss': 0.1363, 'grad_norm': 1.3807580471038818, 'learning_rate': 1.5541237113402063e-05, 'epoch': 4.83}\n",
      "{'loss': 0.1281, 'grad_norm': 0.5109201669692993, 'learning_rate': 1.5515463917525776e-05, 'epoch': 4.86}\n",
      "{'loss': 0.1243, 'grad_norm': 2.6018996238708496, 'learning_rate': 1.5489690721649487e-05, 'epoch': 4.88}\n",
      "{'loss': 0.1644, 'grad_norm': 0.7162432074546814, 'learning_rate': 1.5463917525773197e-05, 'epoch': 4.91}\n",
      "{'loss': 0.1552, 'grad_norm': 0.8886380195617676, 'learning_rate': 1.5438144329896908e-05, 'epoch': 4.93}\n",
      "{'loss': 0.129, 'grad_norm': 0.9232649207115173, 'learning_rate': 1.541237113402062e-05, 'epoch': 4.96}\n",
      "{'loss': 0.1467, 'grad_norm': 0.6040693521499634, 'learning_rate': 1.5386597938144332e-05, 'epoch': 4.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef020eaee5cb4d37b187f0906017ca80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1527621746063232, 'eval_runtime': 3.4811, 'eval_samples_per_second': 51.134, 'eval_steps_per_second': 6.607, 'epoch': 5.0}\n",
      "{'train_runtime': 1015.3287, 'train_samples_per_second': 31.477, 'train_steps_per_second': 3.92, 'train_loss': 0.27967734984262194, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd22542875664eb69f73ac3707e04440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>eval/loss</td><td>▁▄▆██</td></tr><tr><td>eval/runtime</td><td>▁█▆██</td></tr><tr><td>eval/samples_per_second</td><td>█▁▃▁▁</td></tr><tr><td>eval/steps_per_second</td><td>█▁▃▁▁</td></tr><tr><td>eval_loss</td><td>▁▁▄▄▆▆████</td></tr><tr><td>eval_runtime</td><td>▁▁██▆▆████</td></tr><tr><td>eval_samples_per_second</td><td>██▁▁▃▃▁▁▁▁</td></tr><tr><td>eval_steps_per_second</td><td>██▁▁▃▃▁▁▁▁</td></tr><tr><td>global_step</td><td>▁▃▅▆█</td></tr><tr><td>grad_norm</td><td>█▄▂▂▂▂▂▂▂▂▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>learning_rate</td><td>▁▃▅▆██████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆</td></tr><tr><td>loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>saving_checkpoint</td><td>▁▁▁▁▁</td></tr><tr><td>step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>total_flos</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>█▄▂▂▂▂▂▂▂▁▃▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁</td></tr><tr><td>train/learning_rate</td><td>▁▃▅▆██████████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆</td></tr><tr><td>train/loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>train_runtime</td><td>▁</td></tr><tr><td>train_samples_per_second</td><td>▁</td></tr><tr><td>train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4.99625</td></tr><tr><td>eval/loss</td><td>2.15276</td></tr><tr><td>eval/runtime</td><td>3.4811</td></tr><tr><td>eval/samples_per_second</td><td>51.134</td></tr><tr><td>eval/steps_per_second</td><td>6.607</td></tr><tr><td>eval_loss</td><td>2.15276</td></tr><tr><td>eval_runtime</td><td>3.4811</td></tr><tr><td>eval_samples_per_second</td><td>51.134</td></tr><tr><td>eval_steps_per_second</td><td>6.607</td></tr><tr><td>global_step</td><td>998</td></tr><tr><td>grad_norm</td><td>0.60407</td></tr><tr><td>learning_rate</td><td>2e-05</td></tr><tr><td>loss</td><td>0.1467</td></tr><tr><td>saving_checkpoint</td><td>True</td></tr><tr><td>step</td><td>998</td></tr><tr><td>total_flos</td><td>1.871486950938624e+16</td></tr><tr><td>train/epoch</td><td>4.99625</td></tr><tr><td>train/global_step</td><td>998</td></tr><tr><td>train/grad_norm</td><td>0.60407</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.1467</td></tr><tr><td>train_loss</td><td>0.27968</td></tr><tr><td>train_runtime</td><td>1015.3287</td></tr><tr><td>train_samples_per_second</td><td>31.477</td></tr><tr><td>train_steps_per_second</td><td>3.92</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lilac-water-5</strong> at: <a href='https://wandb.ai/davidbzyk/your_project_name/runs/m97lalo7' target=\"_blank\">https://wandb.ai/davidbzyk/your_project_name/runs/m97lalo7</a><br/> View project at: <a href='https://wandb.ai/davidbzyk/your_project_name' target=\"_blank\">https://wandb.ai/davidbzyk/your_project_name</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240804_130249-m97lalo7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ef4ff6abea489da8a47d62c3eecc0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/5.38G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to https://huggingface.co/davidbzyk/simpler-gemma-2-2b\n"
     ]
    }
   ],
   "source": [
    "model.push_to_hub(MODEL_NAME,token=HUGGING_FACE_HUB_TOKEN)\n",
    "tokenizer.push_to_hub(MODEL_NAME,token=HUGGING_FACE_HUB_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA GeForce RTX 3090. Max memory = 23.668 GB.\n",
      "19.348 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "#@title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>Who is Raghee Horner and what is her trading style?\n",
      "\n",
      "Raghee Horner is the brains behind Raghee Horner’s DPMR Indicator. She’s a 30+ year veteran of the trading industry and her methods have helped countless traders over the years. Her background includes 15+ years of experience in top trading rooms and/or as a trusted money manager.\n",
      "\n",
      "Raghee’s a big deal in the trading world. She’s the brains behind Raghee Horner’s DPMR Indicator. Her methods have helped countless traders over the years. Her passion is to help others achieve their full trading potential, one trader at a time.\n",
      "\n",
      "When she’s not trading\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "# Enable native faster inference\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "# Define the question\n",
    "question = \"Who is Raghee Horner and what is her trading style?\"\n",
    "\n",
    "# Format the input\n",
    "formatted_input = question\n",
    "\n",
    "# Tokenize the input\n",
    "inputs = tokenizer(\n",
    "    [formatted_input],\n",
    "    return_tensors=\"pt\"\n",
    ").to(\"cuda\")\n",
    "\n",
    "# Initialize the text streamer\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "\n",
    "# Generate the output using the model\n",
    "_ = model.generate(**inputs, streamer=text_streamer, max_new_tokens=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace the below with how you want to save the model to huggingface/locally  p.s. locally you will fill the hard drive real quick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to https://huggingface.co/simpler-gemma-2-2b\n"
     ]
    }
   ],
   "source": [
    "username = \"davidbzyk\"\n",
    "model_name = \"simpler-gemma-2-2b\"\n",
    "\n",
    "\n",
    "model.push_to_hub(model_name, token=HUGGING_FACE_HUB_TOKEN)\n",
    "tokenizer.push_to_hub(model_name, token=HUGGING_FACE_HUB_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: ##### The current model auto adds a BOS token.\n",
      "Unsloth: ##### Your chat template has a BOS token. We shall remove it temporarily.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Entering directory '/home/dave/Desktop/simpler/simpler-prod-qa/Step-2-Training/step2b-finetune/llama.cpp'\n",
      "I ccache found, compilation results will be cached. Disable with GGML_NO_CCACHE.\n",
      "I llama.cpp build info: \n",
      "I UNAME_S:   Linux\n",
      "I UNAME_P:   x86_64\n",
      "I UNAME_M:   x86_64\n",
      "I CFLAGS:    -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/dave/miniconda3/envs/unsloth_env/include  -I/home/dave/miniconda3/envs/unsloth_env/targets/x86_64-linux/include  -L/home/dave/miniconda3/envs/unsloth_env/targets/x86_64-linux/lib -L/home/dave/miniconda3/envs/unsloth_env/targets/x86_64-linux/lib/stubs -std=c11   -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -fopenmp -Wdouble-promotion -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/dave/miniconda3/envs/unsloth_env/include  -I/home/dave/miniconda3/envs/unsloth_env/targets/x86_64-linux/include  -L/home/dave/miniconda3/envs/unsloth_env/targets/x86_64-linux/lib -L/home/dave/miniconda3/envs/unsloth_env/targets/x86_64-linux/lib/stubs\n",
      "I CXXFLAGS:  -std=c++11 -fPIC -O3 -g -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread -fopenmp -fvisibility-inlines-hidden -fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/dave/miniconda3/envs/unsloth_env/include  -I/home/dave/miniconda3/envs/unsloth_env/targets/x86_64-linux/include  -L/home/dave/miniconda3/envs/unsloth_env/targets/x86_64-linux/lib -L/home/dave/miniconda3/envs/unsloth_env/targets/x86_64-linux/lib/stubs -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Iggml/include -Iggml/src -Iinclude -Isrc -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_OPENMP -DGGML_USE_LLAMAFILE -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/dave/miniconda3/envs/unsloth_env/include  -I/home/dave/miniconda3/envs/unsloth_env/targets/x86_64-linux/include  -L/home/dave/miniconda3/envs/unsloth_env/targets/x86_64-linux/lib -L/home/dave/miniconda3/envs/unsloth_env/targets/x86_64-linux/lib/stubs\n",
      "I NVCCFLAGS: -std=c++11 -O3 -g \n",
      "I LDFLAGS:    -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,--allow-shlib-undefined -Wl,-rpath,/home/dave/miniconda3/envs/unsloth_env/lib -Wl,-rpath-link,/home/dave/miniconda3/envs/unsloth_env/lib -L/home/dave/miniconda3/envs/unsloth_env/lib  -L/home/dave/miniconda3/envs/unsloth_env/targets/x86_64-linux/lib -L/home/dave/miniconda3/envs/unsloth_env/targets/x86_64-linux/lib/stubs\n",
      "I CC:        x86_64-conda-linux-gnu-cc (conda-forge gcc 12.4.0-0) 12.4.0\n",
      "I CXX:       x86_64-conda-linux-gnu-c++ (conda-forge gcc 12.4.0-0) 12.4.0\n",
      "\n",
      "rm -vrf *.dot libllava.a llama-baby-llama llama-batched llama-batched-bench llama-bench llama-benchmark-matmult llama-cli llama-convert-llama2c-to-ggml llama-embedding llama-eval-callback llama-export-lora llama-gbnf-validator llama-gguf llama-gguf-hash llama-gguf-split llama-gritlm llama-imatrix llama-infill llama-llava-cli llama-lookahead llama-lookup llama-lookup-create llama-lookup-merge llama-lookup-stats llama-parallel llama-passkey llama-perplexity llama-q8dot llama-quantize llama-quantize-stats llama-retrieval llama-save-load-state llama-server llama-simple llama-speculative llama-tokenize llama-vdot llama-cvector-generator tests/test-c.o tests/test-autorelease tests/test-backend-ops tests/test-chat-template tests/test-double-float tests/test-grad0 tests/test-grammar-integration tests/test-grammar-parser tests/test-json-schema-to-grammar tests/test-llama-grammar tests/test-model-load-cancel tests/test-opt tests/test-quantize-fns tests/test-quantize-perf tests/test-rope tests/test-sampling tests/test-tokenizer-0 tests/test-tokenizer-1-bpe tests/test-tokenizer-1-spm\n",
      "rm -rvf src/*.o\n",
      "rm -rvf tests/*.o\n",
      "rm -rvf examples/*.o\n",
      "rm -rvf common/*.o\n",
      "rm -rvf *.a\n",
      "rm -rvf *.dll\n",
      "rm -rvf *.so\n",
      "rm -rvf *.dot\n",
      "rm -rvf ggml/*.a\n",
      "rm -rvf ggml/*.dll\n",
      "rm -rvf ggml/*.so\n",
      "rm -vrf ggml/src/*.o\n",
      "rm -rvf common/build-info.cpp\n",
      "rm -vrf ggml/src/ggml-metal-embed.metal\n",
      "rm -vrf ggml/src/ggml-cuda/*.o\n",
      "rm -vrf ggml/src/ggml-cuda/template-instances/*.o\n",
      "rm -rvf libllava.a llama-baby-llama llama-batched llama-batched-bench llama-bench llama-benchmark-matmult llama-cli llama-convert-llama2c-to-ggml llama-embedding llama-eval-callback llama-export-lora llama-gbnf-validator llama-gguf llama-gguf-hash llama-gguf-split llama-gritlm llama-imatrix llama-infill llama-llava-cli llama-lookahead llama-lookup llama-lookup-create llama-lookup-merge llama-lookup-stats llama-parallel llama-passkey llama-perplexity llama-q8dot llama-quantize llama-quantize-stats llama-retrieval llama-save-load-state llama-server llama-simple llama-speculative llama-tokenize llama-vdot llama-cvector-generator tests/test-c.o\n",
      "rm -rvf tests/test-autorelease tests/test-backend-ops tests/test-chat-template tests/test-double-float tests/test-grad0 tests/test-grammar-integration tests/test-grammar-parser tests/test-json-schema-to-grammar tests/test-llama-grammar tests/test-model-load-cancel tests/test-opt tests/test-quantize-fns tests/test-quantize-perf tests/test-rope tests/test-sampling tests/test-tokenizer-0 tests/test-tokenizer-1-bpe tests/test-tokenizer-1-spm\n",
      "rm -f vulkan-shaders-gen ggml/src/ggml-vulkan-shaders.hpp ggml/src/ggml-vulkan-shaders.cpp\n",
      "rm -rvf main quantize quantize-stats perplexity imatrix embedding vdot q8dot convert-llama2c-to-ggml simple batched batched-bench save-load-state server gguf gguf-split eval-callback llama-bench libllava.a llava-cli baby-llama retrieval speculative infill tokenize benchmark-matmult parallel export-lora lookahead lookup passkey gritlm\n",
      "find examples pocs -type f -name \"*.o\" -delete\n",
      "make: Leaving directory '/home/dave/Desktop/simpler/simpler-prod-qa/Step-2-Training/step2b-finetune/llama.cpp'\n",
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 82.11 out of 125.61 RAM for saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 99.30it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Converting gemma2 model. Can use fast conversion = False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
      "   \\\\   /|    [0] Installing llama.cpp will take 3 minutes.\n",
      "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits will take 3 minutes.\n",
      "\\        /    [2] Converting GGUF 16bits to ['q4_k_m', 'q8_0', 'q5_k_m'] will take 10 minutes each.\n",
      " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
      "\n",
      "Unsloth: [0] Installing llama.cpp. This will take 3 minutes...\n",
      "Unsloth: [1] Converting model at simpler-gemma-2-2b-multi into bf16 GGUF format.\n",
      "The output location will be ./simpler-gemma-2-2b-multi/unsloth.BF16.gguf\n",
      "This will take 3 minutes...\n",
      "INFO:hf-to-gguf:Loading model: simpler-gemma-2-2b-multi\n",
      "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "INFO:hf-to-gguf:Exporting model...\n",
      "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00002.safetensors'\n",
      "INFO:hf-to-gguf:token_embd.weight,                 torch.bfloat16 --> BF16, shape = {2304, 256000}\n",
      "INFO:hf-to-gguf:blk.0.attn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.0.ffn_down.weight,             torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.0.ffn_gate.weight,             torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.0.ffn_up.weight,               torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.0.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.0.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.0.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.weight,               torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.0.attn_output.weight,          torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.weight,               torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.weight,               torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.1.ffn_down.weight,             torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.1.ffn_gate.weight,             torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.1.ffn_up.weight,               torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.1.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.1.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.1.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.weight,               torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_output.weight,          torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.weight,               torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.weight,               torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.10.attn_norm.weight,           torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.10.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.10.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.10.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.10.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.10.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.10.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.10.attn_output.weight,         torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.weight,              torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_norm.weight,           torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.11.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.11.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.11.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.11.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.11.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.11.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_output.weight,         torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.weight,              torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_norm.weight,           torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.12.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.12.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.12.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.12.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.12.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.12.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_output.weight,         torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.weight,              torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_norm.weight,           torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.13.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.13.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.13.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.13.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.13.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.13.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_output.weight,         torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.weight,              torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_norm.weight,           torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.14.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.14.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.14.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.14.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.14.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.14.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_output.weight,         torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.weight,              torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_norm.weight,           torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.15.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.15.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.15.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.15.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.15.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.15.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_output.weight,         torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.weight,              torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_norm.weight,           torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.16.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.16.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.16.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.16.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.16.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.16.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_output.weight,         torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.weight,              torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_norm.weight,           torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.17.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.17.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.17.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.17.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.17.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.17.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_output.weight,         torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.weight,              torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_norm.weight,           torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.18.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.18.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.18.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.18.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.18.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.18.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.18.attn_k.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_output.weight,         torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.18.attn_q.weight,              torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.18.attn_v.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_norm.weight,           torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.19.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.19.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.19.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.19.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.19.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.19.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.19.attn_k.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_output.weight,         torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.19.attn_q.weight,              torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.19.attn_v.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.2.ffn_down.weight,             torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.2.ffn_gate.weight,             torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.2.ffn_up.weight,               torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.2.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.2.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.2.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.weight,               torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_output.weight,          torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.weight,               torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.weight,               torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.20.attn_norm.weight,           torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.20.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.20.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.20.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.20.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.20.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.20.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.20.attn_k.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.20.attn_output.weight,         torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.20.attn_q.weight,              torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.20.attn_v.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.21.attn_norm.weight,           torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.21.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.21.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.21.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.21.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.21.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.21.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.21.attn_k.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.21.attn_output.weight,         torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.21.attn_q.weight,              torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.21.attn_v.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_norm.weight,           torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.22.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.22.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.22.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.22.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.22.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.22.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.22.attn_k.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_output.weight,         torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.22.attn_q.weight,              torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.22.attn_v.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_norm.weight,           torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.23.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.23.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.23.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.23.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.23.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.23.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.23.attn_k.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_output.weight,         torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.23.attn_q.weight,              torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.23.attn_v.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.24.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.24.attn_k.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_output.weight,         torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.24.attn_q.weight,              torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.24.attn_v.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.3.ffn_down.weight,             torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.3.ffn_gate.weight,             torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.3.ffn_up.weight,               torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.3.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.3.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.3.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.weight,               torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_output.weight,          torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.weight,               torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.weight,               torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.4.ffn_down.weight,             torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.4.ffn_gate.weight,             torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.4.ffn_up.weight,               torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.4.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.4.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.4.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.weight,               torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_output.weight,          torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.weight,               torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.weight,               torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.5.ffn_down.weight,             torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.5.ffn_gate.weight,             torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.5.ffn_up.weight,               torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.5.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.5.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.5.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.weight,               torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_output.weight,          torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.weight,               torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.weight,               torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.6.ffn_down.weight,             torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.6.ffn_gate.weight,             torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.6.ffn_up.weight,               torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.6.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.6.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.6.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.weight,               torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_output.weight,          torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.weight,               torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.weight,               torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.7.ffn_down.weight,             torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.7.ffn_gate.weight,             torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.7.ffn_up.weight,               torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.7.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.7.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.7.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.weight,               torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_output.weight,          torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.weight,               torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.weight,               torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.8.ffn_down.weight,             torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.8.ffn_gate.weight,             torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.8.ffn_up.weight,               torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.8.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.8.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.8.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.weight,               torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_output.weight,          torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.weight,               torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.weight,               torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.9.ffn_down.weight,             torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.9.ffn_gate.weight,             torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.9.ffn_up.weight,               torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.9.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.9.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.9.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.weight,               torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_output.weight,          torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.weight,               torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.weight,               torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00002.safetensors'\n",
      "INFO:hf-to-gguf:blk.24.attn_norm.weight,           torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.24.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.24.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.24.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.24.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.24.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.25.attn_norm.weight,           torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.25.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {9216, 2304}\n",
      "INFO:hf-to-gguf:blk.25.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.25.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {2304, 9216}\n",
      "INFO:hf-to-gguf:blk.25.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.25.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.25.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:blk.25.attn_k.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_output.weight,         torch.bfloat16 --> BF16, shape = {2048, 2304}\n",
      "INFO:hf-to-gguf:blk.25.attn_q.weight,              torch.bfloat16 --> BF16, shape = {2304, 2048}\n",
      "INFO:hf-to-gguf:blk.25.attn_v.weight,              torch.bfloat16 --> BF16, shape = {2304, 1024}\n",
      "INFO:hf-to-gguf:output_norm.weight,                torch.bfloat16 --> F32, shape = {2304}\n",
      "INFO:hf-to-gguf:Set meta model\n",
      "INFO:hf-to-gguf:Set model parameters\n",
      "INFO:hf-to-gguf:Set model tokenizer\n",
      "INFO:gguf.vocab:Setting special token type bos to 2\n",
      "INFO:gguf.vocab:Setting special token type eos to 1\n",
      "INFO:gguf.vocab:Setting special token type unk to 3\n",
      "INFO:gguf.vocab:Setting special token type pad to 0\n",
      "INFO:gguf.vocab:Setting add_bos_token to True\n",
      "INFO:gguf.vocab:Setting add_eos_token to False\n",
      "INFO:gguf.vocab:Setting chat_template to {% if messages[0]['role'] == 'system' %}{{ raise_exception('System role not supported') }}{% endif %}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == 'assistant') %}{% set role = 'model' %}{% else %}{% set role = message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\n",
      "' + message['content'] | trim + '<end_of_turn>\n",
      "' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\n",
      "'}}{% endif %}\n",
      "INFO:hf-to-gguf:Set model quantization version\n",
      "INFO:gguf.gguf_writer:Writing the following files:\n",
      "INFO:gguf.gguf_writer:simpler-gemma-2-2b-multi/unsloth.BF16.gguf: n_tensors = 288, total_size = 5.2G\n",
      "Writing: 100%|██████████| 5.23G/5.23G [00:09<00:00, 544Mbyte/s]\n",
      "INFO:hf-to-gguf:Model successfully exported to simpler-gemma-2-2b-multi/unsloth.BF16.gguf\n",
      "Unsloth: Conversion completed! Output location: ./simpler-gemma-2-2b-multi/unsloth.BF16.gguf\n",
      "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This will take 20 minutes...\n",
      "main: build = 3509 (ecf6b7f2)\n",
      "main: built with x86_64-conda-linux-gnu-cc (conda-forge gcc 12.4.0-0) 12.4.0 for x86_64-conda-linux-gnu\n",
      "main: quantizing './simpler-gemma-2-2b-multi/unsloth.BF16.gguf' to './simpler-gemma-2-2b-multi/unsloth.Q4_K_M.gguf' as Q4_K_M using 64 threads\n",
      "llama_model_loader: loaded meta data with 34 key-value pairs and 288 tensors from ./simpler-gemma-2-2b-multi/unsloth.BF16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = gemma2\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Gemma 2 2b It Bnb 4bit\n",
      "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
      "llama_model_loader: - kv   4:                           general.finetune str              = it-bnb-4bit\n",
      "llama_model_loader: - kv   5:                           general.basename str              = gemma-2\n",
      "llama_model_loader: - kv   6:                         general.size_label str              = 2B\n",
      "llama_model_loader: - kv   7:                      gemma2.context_length u32              = 8192\n",
      "llama_model_loader: - kv   8:                    gemma2.embedding_length u32              = 2304\n",
      "llama_model_loader: - kv   9:                         gemma2.block_count u32              = 26\n",
      "llama_model_loader: - kv  10:                 gemma2.feed_forward_length u32              = 9216\n",
      "llama_model_loader: - kv  11:                gemma2.attention.head_count u32              = 8\n",
      "llama_model_loader: - kv  12:             gemma2.attention.head_count_kv u32              = 4\n",
      "llama_model_loader: - kv  13:    gemma2.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  14:                gemma2.attention.key_length u32              = 256\n",
      "llama_model_loader: - kv  15:              gemma2.attention.value_length u32              = 256\n",
      "llama_model_loader: - kv  16:                          general.file_type u32              = 32\n",
      "llama_model_loader: - kv  17:              gemma2.attn_logit_softcapping f32              = 50.000000\n",
      "llama_model_loader: - kv  18:             gemma2.final_logit_softcapping f32              = 30.000000\n",
      "llama_model_loader: - kv  19:            gemma2.attention.sliding_window u32              = 4096\n",
      "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,256000]  = [\"<pad>\", \"<eos>\", \"<bos>\", \"<unk>\", ...\n",
      "llama_model_loader: - kv  23:                      tokenizer.ggml.scores arr[f32,256000]  = [-1000.000000, -1000.000000, -1000.00...\n",
      "llama_model_loader: - kv  24:                  tokenizer.ggml.token_type arr[i32,256000]  = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\n",
      "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 2\n",
      "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 1\n",
      "llama_model_loader: - kv  27:            tokenizer.ggml.unknown_token_id u32              = 3\n",
      "llama_model_loader: - kv  28:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  29:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  30:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  31:                    tokenizer.chat_template str              = {% if messages[0]['role'] == 'system'...\n",
      "llama_model_loader: - kv  32:            tokenizer.ggml.add_space_prefix bool             = false\n",
      "llama_model_loader: - kv  33:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:  105 tensors\n",
      "llama_model_loader: - type bf16:  183 tensors\n",
      "[   1/ 288]                    token_embd.weight - [ 2304, 256000,     1,     1], type =   bf16, converting to q6_K .. size =  1125.00 MiB ->   461.43 MiB\n",
      "[   2/ 288]               blk.0.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[   3/ 288]                blk.0.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[   4/ 288]                blk.0.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[   5/ 288]                  blk.0.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[   6/ 288]     blk.0.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[   7/ 288]           blk.0.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[   8/ 288]                blk.0.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[   9/ 288]                  blk.0.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[  10/ 288]             blk.0.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[  11/ 288]                  blk.0.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[  12/ 288]                  blk.0.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[  13/ 288]               blk.1.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  14/ 288]                blk.1.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[  15/ 288]                blk.1.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[  16/ 288]                  blk.1.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[  17/ 288]     blk.1.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  18/ 288]           blk.1.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  19/ 288]                blk.1.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  20/ 288]                  blk.1.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[  21/ 288]             blk.1.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[  22/ 288]                  blk.1.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[  23/ 288]                  blk.1.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[  24/ 288]              blk.10.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  25/ 288]               blk.10.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[  26/ 288]               blk.10.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[  27/ 288]                 blk.10.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[  28/ 288]    blk.10.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  29/ 288]          blk.10.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  30/ 288]               blk.10.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  31/ 288]                 blk.10.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[  32/ 288]            blk.10.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[  33/ 288]                 blk.10.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[  34/ 288]                 blk.10.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[  35/ 288]              blk.11.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  36/ 288]               blk.11.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[  37/ 288]               blk.11.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[  38/ 288]                 blk.11.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[  39/ 288]    blk.11.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  40/ 288]          blk.11.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  41/ 288]               blk.11.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  42/ 288]                 blk.11.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[  43/ 288]            blk.11.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[  44/ 288]                 blk.11.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[  45/ 288]                 blk.11.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[  46/ 288]              blk.12.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  47/ 288]               blk.12.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[  48/ 288]               blk.12.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[  49/ 288]                 blk.12.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[  50/ 288]    blk.12.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  51/ 288]          blk.12.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  52/ 288]               blk.12.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  53/ 288]                 blk.12.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[  54/ 288]            blk.12.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[  55/ 288]                 blk.12.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[  56/ 288]                 blk.12.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[  57/ 288]              blk.13.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  58/ 288]               blk.13.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[  59/ 288]               blk.13.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[  60/ 288]                 blk.13.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[  61/ 288]    blk.13.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  62/ 288]          blk.13.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  63/ 288]               blk.13.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  64/ 288]                 blk.13.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[  65/ 288]            blk.13.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[  66/ 288]                 blk.13.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[  67/ 288]                 blk.13.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[  68/ 288]              blk.14.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  69/ 288]               blk.14.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[  70/ 288]               blk.14.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[  71/ 288]                 blk.14.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[  72/ 288]    blk.14.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  73/ 288]          blk.14.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  74/ 288]               blk.14.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  75/ 288]                 blk.14.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[  76/ 288]            blk.14.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[  77/ 288]                 blk.14.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[  78/ 288]                 blk.14.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[  79/ 288]              blk.15.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  80/ 288]               blk.15.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[  81/ 288]               blk.15.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[  82/ 288]                 blk.15.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[  83/ 288]    blk.15.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  84/ 288]          blk.15.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  85/ 288]               blk.15.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  86/ 288]                 blk.15.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[  87/ 288]            blk.15.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[  88/ 288]                 blk.15.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[  89/ 288]                 blk.15.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[  90/ 288]              blk.16.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  91/ 288]               blk.16.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[  92/ 288]               blk.16.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[  93/ 288]                 blk.16.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[  94/ 288]    blk.16.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  95/ 288]          blk.16.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  96/ 288]               blk.16.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  97/ 288]                 blk.16.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[  98/ 288]            blk.16.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[  99/ 288]                 blk.16.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 100/ 288]                 blk.16.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[ 101/ 288]              blk.17.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 102/ 288]               blk.17.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 103/ 288]               blk.17.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 104/ 288]                 blk.17.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 105/ 288]    blk.17.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 106/ 288]          blk.17.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 107/ 288]               blk.17.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 108/ 288]                 blk.17.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 109/ 288]            blk.17.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 110/ 288]                 blk.17.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 111/ 288]                 blk.17.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 112/ 288]              blk.18.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 113/ 288]               blk.18.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 114/ 288]               blk.18.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 115/ 288]                 blk.18.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 116/ 288]    blk.18.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 117/ 288]          blk.18.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 118/ 288]               blk.18.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 119/ 288]                 blk.18.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 120/ 288]            blk.18.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 121/ 288]                 blk.18.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 122/ 288]                 blk.18.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 123/ 288]              blk.19.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 124/ 288]               blk.19.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[ 125/ 288]               blk.19.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 126/ 288]                 blk.19.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 127/ 288]    blk.19.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 128/ 288]          blk.19.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 129/ 288]               blk.19.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 130/ 288]                 blk.19.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 131/ 288]            blk.19.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 132/ 288]                 blk.19.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 133/ 288]                 blk.19.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[ 134/ 288]               blk.2.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 135/ 288]                blk.2.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 136/ 288]                blk.2.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 137/ 288]                  blk.2.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 138/ 288]     blk.2.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 139/ 288]           blk.2.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 140/ 288]                blk.2.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 141/ 288]                  blk.2.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 142/ 288]             blk.2.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 143/ 288]                  blk.2.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 144/ 288]                  blk.2.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 145/ 288]              blk.20.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 146/ 288]               blk.20.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 147/ 288]               blk.20.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 148/ 288]                 blk.20.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 149/ 288]    blk.20.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 150/ 288]          blk.20.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 151/ 288]               blk.20.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 152/ 288]                 blk.20.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 153/ 288]            blk.20.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 154/ 288]                 blk.20.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 155/ 288]                 blk.20.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 156/ 288]              blk.21.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 157/ 288]               blk.21.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[ 158/ 288]               blk.21.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 159/ 288]                 blk.21.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 160/ 288]    blk.21.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 161/ 288]          blk.21.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 162/ 288]               blk.21.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 163/ 288]                 blk.21.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 164/ 288]            blk.21.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 165/ 288]                 blk.21.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 166/ 288]                 blk.21.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[ 167/ 288]              blk.22.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 168/ 288]               blk.22.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 169/ 288]               blk.22.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 170/ 288]                 blk.22.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 171/ 288]    blk.22.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 172/ 288]          blk.22.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 173/ 288]               blk.22.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 174/ 288]                 blk.22.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 175/ 288]            blk.22.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 176/ 288]                 blk.22.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 177/ 288]                 blk.22.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 178/ 288]              blk.23.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 179/ 288]               blk.23.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 180/ 288]               blk.23.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 181/ 288]                 blk.23.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 182/ 288]    blk.23.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 183/ 288]          blk.23.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 184/ 288]               blk.23.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 185/ 288]                 blk.23.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 186/ 288]            blk.23.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 187/ 288]                 blk.23.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 188/ 288]                 blk.23.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 189/ 288]               blk.24.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 190/ 288]                 blk.24.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 191/ 288]            blk.24.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 192/ 288]                 blk.24.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 193/ 288]                 blk.24.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[ 194/ 288]               blk.3.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 195/ 288]                blk.3.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[ 196/ 288]                blk.3.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 197/ 288]                  blk.3.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 198/ 288]     blk.3.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 199/ 288]           blk.3.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 200/ 288]                blk.3.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 201/ 288]                  blk.3.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 202/ 288]             blk.3.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 203/ 288]                  blk.3.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 204/ 288]                  blk.3.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 205/ 288]               blk.4.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 206/ 288]                blk.4.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 207/ 288]                blk.4.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 208/ 288]                  blk.4.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 209/ 288]     blk.4.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 210/ 288]           blk.4.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 211/ 288]                blk.4.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 212/ 288]                  blk.4.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 213/ 288]             blk.4.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 214/ 288]                  blk.4.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 215/ 288]                  blk.4.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 216/ 288]               blk.5.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 217/ 288]                blk.5.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 218/ 288]                blk.5.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 219/ 288]                  blk.5.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 220/ 288]     blk.5.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 221/ 288]           blk.5.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 222/ 288]                blk.5.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 223/ 288]                  blk.5.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 224/ 288]             blk.5.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 225/ 288]                  blk.5.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 226/ 288]                  blk.5.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[ 227/ 288]               blk.6.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 228/ 288]                blk.6.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[ 229/ 288]                blk.6.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 230/ 288]                  blk.6.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 231/ 288]     blk.6.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 232/ 288]           blk.6.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 233/ 288]                blk.6.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 234/ 288]                  blk.6.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 235/ 288]             blk.6.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 236/ 288]                  blk.6.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 237/ 288]                  blk.6.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 238/ 288]               blk.7.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 239/ 288]                blk.7.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 240/ 288]                blk.7.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 241/ 288]                  blk.7.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 242/ 288]     blk.7.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 243/ 288]           blk.7.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 244/ 288]                blk.7.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 245/ 288]                  blk.7.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 246/ 288]             blk.7.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 247/ 288]                  blk.7.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 248/ 288]                  blk.7.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[ 249/ 288]               blk.8.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 250/ 288]                blk.8.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[ 251/ 288]                blk.8.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 252/ 288]                  blk.8.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 253/ 288]     blk.8.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 254/ 288]           blk.8.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 255/ 288]                blk.8.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 256/ 288]                  blk.8.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 257/ 288]             blk.8.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 258/ 288]                  blk.8.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 259/ 288]                  blk.8.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[ 260/ 288]               blk.9.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 261/ 288]                blk.9.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[ 262/ 288]                blk.9.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 263/ 288]                  blk.9.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 264/ 288]     blk.9.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 265/ 288]           blk.9.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 266/ 288]                blk.9.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 267/ 288]                  blk.9.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 268/ 288]             blk.9.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 269/ 288]                  blk.9.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 270/ 288]                  blk.9.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[ 271/ 288]              blk.24.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 272/ 288]               blk.24.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[ 273/ 288]                 blk.24.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 274/ 288]    blk.24.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 275/ 288]          blk.24.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 276/ 288]               blk.24.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 277/ 288]              blk.25.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 278/ 288]               blk.25.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[ 279/ 288]               blk.25.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 280/ 288]                 blk.25.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q4_K .. size =    40.50 MiB ->    11.39 MiB\n",
      "[ 281/ 288]    blk.25.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 282/ 288]          blk.25.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 283/ 288]               blk.25.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 284/ 288]                 blk.25.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     4.50 MiB ->     1.27 MiB\n",
      "[ 285/ 288]            blk.25.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 286/ 288]                 blk.25.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     9.00 MiB ->     2.53 MiB\n",
      "[ 287/ 288]                 blk.25.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[ 288/ 288]                   output_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "llama_model_quantize_internal: model size  =  4986.92 MB\n",
      "llama_model_quantize_internal: quant size  =  1623.67 MB\n",
      "\n",
      "main: quantize time =  8235.47 ms\n",
      "main:    total time =  8235.47 ms\n",
      "Unsloth: Conversion completed! Output location: ./simpler-gemma-2-2b-multi/unsloth.Q4_K_M.gguf\n",
      "Unsloth: [2] Converting GGUF 16bit into q8_0. This will take 20 minutes...\n",
      "main: build = 3509 (ecf6b7f2)\n",
      "main: built with x86_64-conda-linux-gnu-cc (conda-forge gcc 12.4.0-0) 12.4.0 for x86_64-conda-linux-gnu\n",
      "main: quantizing './simpler-gemma-2-2b-multi/unsloth.BF16.gguf' to './simpler-gemma-2-2b-multi/unsloth.Q8_0.gguf' as Q8_0 using 64 threads\n",
      "llama_model_loader: loaded meta data with 34 key-value pairs and 288 tensors from ./simpler-gemma-2-2b-multi/unsloth.BF16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = gemma2\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Gemma 2 2b It Bnb 4bit\n",
      "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
      "llama_model_loader: - kv   4:                           general.finetune str              = it-bnb-4bit\n",
      "llama_model_loader: - kv   5:                           general.basename str              = gemma-2\n",
      "llama_model_loader: - kv   6:                         general.size_label str              = 2B\n",
      "llama_model_loader: - kv   7:                      gemma2.context_length u32              = 8192\n",
      "llama_model_loader: - kv   8:                    gemma2.embedding_length u32              = 2304\n",
      "llama_model_loader: - kv   9:                         gemma2.block_count u32              = 26\n",
      "llama_model_loader: - kv  10:                 gemma2.feed_forward_length u32              = 9216\n",
      "llama_model_loader: - kv  11:                gemma2.attention.head_count u32              = 8\n",
      "llama_model_loader: - kv  12:             gemma2.attention.head_count_kv u32              = 4\n",
      "llama_model_loader: - kv  13:    gemma2.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  14:                gemma2.attention.key_length u32              = 256\n",
      "llama_model_loader: - kv  15:              gemma2.attention.value_length u32              = 256\n",
      "llama_model_loader: - kv  16:                          general.file_type u32              = 32\n",
      "llama_model_loader: - kv  17:              gemma2.attn_logit_softcapping f32              = 50.000000\n",
      "llama_model_loader: - kv  18:             gemma2.final_logit_softcapping f32              = 30.000000\n",
      "llama_model_loader: - kv  19:            gemma2.attention.sliding_window u32              = 4096\n",
      "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,256000]  = [\"<pad>\", \"<eos>\", \"<bos>\", \"<unk>\", ...\n",
      "llama_model_loader: - kv  23:                      tokenizer.ggml.scores arr[f32,256000]  = [-1000.000000, -1000.000000, -1000.00...\n",
      "llama_model_loader: - kv  24:                  tokenizer.ggml.token_type arr[i32,256000]  = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\n",
      "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 2\n",
      "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 1\n",
      "llama_model_loader: - kv  27:            tokenizer.ggml.unknown_token_id u32              = 3\n",
      "llama_model_loader: - kv  28:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  29:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  30:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  31:                    tokenizer.chat_template str              = {% if messages[0]['role'] == 'system'...\n",
      "llama_model_loader: - kv  32:            tokenizer.ggml.add_space_prefix bool             = false\n",
      "llama_model_loader: - kv  33:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:  105 tensors\n",
      "llama_model_loader: - type bf16:  183 tensors\n",
      "[   1/ 288]                    token_embd.weight - [ 2304, 256000,     1,     1], type =   bf16, converting to q8_0 .. size =  1125.00 MiB ->   597.66 MiB\n",
      "[   2/ 288]               blk.0.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[   3/ 288]                blk.0.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[   4/ 288]                blk.0.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[   5/ 288]                  blk.0.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[   6/ 288]     blk.0.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[   7/ 288]           blk.0.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[   8/ 288]                blk.0.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[   9/ 288]                  blk.0.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[  10/ 288]             blk.0.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[  11/ 288]                  blk.0.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[  12/ 288]                  blk.0.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[  13/ 288]               blk.1.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  14/ 288]                blk.1.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[  15/ 288]                blk.1.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[  16/ 288]                  blk.1.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[  17/ 288]     blk.1.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  18/ 288]           blk.1.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  19/ 288]                blk.1.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  20/ 288]                  blk.1.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[  21/ 288]             blk.1.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[  22/ 288]                  blk.1.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[  23/ 288]                  blk.1.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[  24/ 288]              blk.10.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  25/ 288]               blk.10.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[  26/ 288]               blk.10.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[  27/ 288]                 blk.10.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[  28/ 288]    blk.10.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  29/ 288]          blk.10.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  30/ 288]               blk.10.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  31/ 288]                 blk.10.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[  32/ 288]            blk.10.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[  33/ 288]                 blk.10.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[  34/ 288]                 blk.10.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[  35/ 288]              blk.11.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  36/ 288]               blk.11.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[  37/ 288]               blk.11.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[  38/ 288]                 blk.11.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[  39/ 288]    blk.11.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  40/ 288]          blk.11.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  41/ 288]               blk.11.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  42/ 288]                 blk.11.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[  43/ 288]            blk.11.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[  44/ 288]                 blk.11.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[  45/ 288]                 blk.11.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[  46/ 288]              blk.12.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  47/ 288]               blk.12.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[  48/ 288]               blk.12.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[  49/ 288]                 blk.12.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[  50/ 288]    blk.12.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  51/ 288]          blk.12.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  52/ 288]               blk.12.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  53/ 288]                 blk.12.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[  54/ 288]            blk.12.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[  55/ 288]                 blk.12.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[  56/ 288]                 blk.12.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[  57/ 288]              blk.13.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  58/ 288]               blk.13.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[  59/ 288]               blk.13.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[  60/ 288]                 blk.13.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[  61/ 288]    blk.13.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  62/ 288]          blk.13.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  63/ 288]               blk.13.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  64/ 288]                 blk.13.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[  65/ 288]            blk.13.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[  66/ 288]                 blk.13.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[  67/ 288]                 blk.13.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[  68/ 288]              blk.14.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  69/ 288]               blk.14.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[  70/ 288]               blk.14.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[  71/ 288]                 blk.14.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[  72/ 288]    blk.14.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  73/ 288]          blk.14.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  74/ 288]               blk.14.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  75/ 288]                 blk.14.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[  76/ 288]            blk.14.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[  77/ 288]                 blk.14.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[  78/ 288]                 blk.14.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[  79/ 288]              blk.15.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  80/ 288]               blk.15.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[  81/ 288]               blk.15.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[  82/ 288]                 blk.15.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[  83/ 288]    blk.15.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  84/ 288]          blk.15.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  85/ 288]               blk.15.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  86/ 288]                 blk.15.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[  87/ 288]            blk.15.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[  88/ 288]                 blk.15.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[  89/ 288]                 blk.15.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[  90/ 288]              blk.16.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  91/ 288]               blk.16.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[  92/ 288]               blk.16.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[  93/ 288]                 blk.16.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[  94/ 288]    blk.16.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  95/ 288]          blk.16.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  96/ 288]               blk.16.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  97/ 288]                 blk.16.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[  98/ 288]            blk.16.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[  99/ 288]                 blk.16.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 100/ 288]                 blk.16.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 101/ 288]              blk.17.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 102/ 288]               blk.17.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 103/ 288]               blk.17.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 104/ 288]                 blk.17.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 105/ 288]    blk.17.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 106/ 288]          blk.17.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 107/ 288]               blk.17.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 108/ 288]                 blk.17.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 109/ 288]            blk.17.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 110/ 288]                 blk.17.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 111/ 288]                 blk.17.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 112/ 288]              blk.18.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 113/ 288]               blk.18.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 114/ 288]               blk.18.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 115/ 288]                 blk.18.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 116/ 288]    blk.18.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 117/ 288]          blk.18.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 118/ 288]               blk.18.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 119/ 288]                 blk.18.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 120/ 288]            blk.18.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 121/ 288]                 blk.18.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 122/ 288]                 blk.18.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 123/ 288]              blk.19.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 124/ 288]               blk.19.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 125/ 288]               blk.19.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 126/ 288]                 blk.19.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 127/ 288]    blk.19.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 128/ 288]          blk.19.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 129/ 288]               blk.19.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 130/ 288]                 blk.19.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 131/ 288]            blk.19.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 132/ 288]                 blk.19.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 133/ 288]                 blk.19.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 134/ 288]               blk.2.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 135/ 288]                blk.2.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 136/ 288]                blk.2.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 137/ 288]                  blk.2.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 138/ 288]     blk.2.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 139/ 288]           blk.2.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 140/ 288]                blk.2.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 141/ 288]                  blk.2.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 142/ 288]             blk.2.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 143/ 288]                  blk.2.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 144/ 288]                  blk.2.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 145/ 288]              blk.20.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 146/ 288]               blk.20.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 147/ 288]               blk.20.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 148/ 288]                 blk.20.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 149/ 288]    blk.20.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 150/ 288]          blk.20.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 151/ 288]               blk.20.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 152/ 288]                 blk.20.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 153/ 288]            blk.20.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 154/ 288]                 blk.20.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 155/ 288]                 blk.20.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 156/ 288]              blk.21.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 157/ 288]               blk.21.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 158/ 288]               blk.21.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 159/ 288]                 blk.21.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 160/ 288]    blk.21.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 161/ 288]          blk.21.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 162/ 288]               blk.21.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 163/ 288]                 blk.21.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 164/ 288]            blk.21.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 165/ 288]                 blk.21.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 166/ 288]                 blk.21.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 167/ 288]              blk.22.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 168/ 288]               blk.22.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 169/ 288]               blk.22.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 170/ 288]                 blk.22.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 171/ 288]    blk.22.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 172/ 288]          blk.22.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 173/ 288]               blk.22.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 174/ 288]                 blk.22.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 175/ 288]            blk.22.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 176/ 288]                 blk.22.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 177/ 288]                 blk.22.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 178/ 288]              blk.23.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 179/ 288]               blk.23.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 180/ 288]               blk.23.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 181/ 288]                 blk.23.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 182/ 288]    blk.23.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 183/ 288]          blk.23.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 184/ 288]               blk.23.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 185/ 288]                 blk.23.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 186/ 288]            blk.23.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 187/ 288]                 blk.23.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 188/ 288]                 blk.23.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 189/ 288]               blk.24.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 190/ 288]                 blk.24.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 191/ 288]            blk.24.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 192/ 288]                 blk.24.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 193/ 288]                 blk.24.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 194/ 288]               blk.3.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 195/ 288]                blk.3.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 196/ 288]                blk.3.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 197/ 288]                  blk.3.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 198/ 288]     blk.3.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 199/ 288]           blk.3.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 200/ 288]                blk.3.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 201/ 288]                  blk.3.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 202/ 288]             blk.3.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 203/ 288]                  blk.3.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 204/ 288]                  blk.3.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 205/ 288]               blk.4.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 206/ 288]                blk.4.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 207/ 288]                blk.4.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 208/ 288]                  blk.4.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 209/ 288]     blk.4.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 210/ 288]           blk.4.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 211/ 288]                blk.4.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 212/ 288]                  blk.4.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 213/ 288]             blk.4.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 214/ 288]                  blk.4.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 215/ 288]                  blk.4.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 216/ 288]               blk.5.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 217/ 288]                blk.5.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 218/ 288]                blk.5.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 219/ 288]                  blk.5.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 220/ 288]     blk.5.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 221/ 288]           blk.5.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 222/ 288]                blk.5.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 223/ 288]                  blk.5.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 224/ 288]             blk.5.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 225/ 288]                  blk.5.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 226/ 288]                  blk.5.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 227/ 288]               blk.6.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 228/ 288]                blk.6.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 229/ 288]                blk.6.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 230/ 288]                  blk.6.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 231/ 288]     blk.6.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 232/ 288]           blk.6.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 233/ 288]                blk.6.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 234/ 288]                  blk.6.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 235/ 288]             blk.6.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 236/ 288]                  blk.6.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 237/ 288]                  blk.6.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 238/ 288]               blk.7.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 239/ 288]                blk.7.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 240/ 288]                blk.7.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 241/ 288]                  blk.7.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 242/ 288]     blk.7.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 243/ 288]           blk.7.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 244/ 288]                blk.7.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 245/ 288]                  blk.7.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 246/ 288]             blk.7.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 247/ 288]                  blk.7.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 248/ 288]                  blk.7.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 249/ 288]               blk.8.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 250/ 288]                blk.8.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 251/ 288]                blk.8.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 252/ 288]                  blk.8.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 253/ 288]     blk.8.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 254/ 288]           blk.8.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 255/ 288]                blk.8.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 256/ 288]                  blk.8.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 257/ 288]             blk.8.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 258/ 288]                  blk.8.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 259/ 288]                  blk.8.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 260/ 288]               blk.9.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 261/ 288]                blk.9.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 262/ 288]                blk.9.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 263/ 288]                  blk.9.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 264/ 288]     blk.9.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 265/ 288]           blk.9.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 266/ 288]                blk.9.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 267/ 288]                  blk.9.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 268/ 288]             blk.9.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 269/ 288]                  blk.9.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 270/ 288]                  blk.9.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 271/ 288]              blk.24.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 272/ 288]               blk.24.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 273/ 288]                 blk.24.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 274/ 288]    blk.24.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 275/ 288]          blk.24.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 276/ 288]               blk.24.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 277/ 288]              blk.25.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 278/ 288]               blk.25.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 279/ 288]               blk.25.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 280/ 288]                 blk.25.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q8_0 .. size =    40.50 MiB ->    21.52 MiB\n",
      "[ 281/ 288]    blk.25.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 282/ 288]          blk.25.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 283/ 288]               blk.25.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 284/ 288]                 blk.25.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 285/ 288]            blk.25.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 286/ 288]                 blk.25.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     9.00 MiB ->     4.78 MiB\n",
      "[ 287/ 288]                 blk.25.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q8_0 .. size =     4.50 MiB ->     2.39 MiB\n",
      "[ 288/ 288]                   output_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "llama_model_quantize_internal: model size  =  4986.92 MB\n",
      "llama_model_quantize_internal: quant size  =  2649.74 MB\n",
      "\n",
      "main: quantize time =  3633.17 ms\n",
      "main:    total time =  3633.17 ms\n",
      "Unsloth: Conversion completed! Output location: ./simpler-gemma-2-2b-multi/unsloth.Q8_0.gguf\n",
      "Unsloth: [2] Converting GGUF 16bit into q5_k_m. This will take 20 minutes...\n",
      "main: build = 3509 (ecf6b7f2)\n",
      "main: built with x86_64-conda-linux-gnu-cc (conda-forge gcc 12.4.0-0) 12.4.0 for x86_64-conda-linux-gnu\n",
      "main: quantizing './simpler-gemma-2-2b-multi/unsloth.BF16.gguf' to './simpler-gemma-2-2b-multi/unsloth.Q5_K_M.gguf' as Q5_K_M using 64 threads\n",
      "llama_model_loader: loaded meta data with 34 key-value pairs and 288 tensors from ./simpler-gemma-2-2b-multi/unsloth.BF16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = gemma2\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Gemma 2 2b It Bnb 4bit\n",
      "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
      "llama_model_loader: - kv   4:                           general.finetune str              = it-bnb-4bit\n",
      "llama_model_loader: - kv   5:                           general.basename str              = gemma-2\n",
      "llama_model_loader: - kv   6:                         general.size_label str              = 2B\n",
      "llama_model_loader: - kv   7:                      gemma2.context_length u32              = 8192\n",
      "llama_model_loader: - kv   8:                    gemma2.embedding_length u32              = 2304\n",
      "llama_model_loader: - kv   9:                         gemma2.block_count u32              = 26\n",
      "llama_model_loader: - kv  10:                 gemma2.feed_forward_length u32              = 9216\n",
      "llama_model_loader: - kv  11:                gemma2.attention.head_count u32              = 8\n",
      "llama_model_loader: - kv  12:             gemma2.attention.head_count_kv u32              = 4\n",
      "llama_model_loader: - kv  13:    gemma2.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  14:                gemma2.attention.key_length u32              = 256\n",
      "llama_model_loader: - kv  15:              gemma2.attention.value_length u32              = 256\n",
      "llama_model_loader: - kv  16:                          general.file_type u32              = 32\n",
      "llama_model_loader: - kv  17:              gemma2.attn_logit_softcapping f32              = 50.000000\n",
      "llama_model_loader: - kv  18:             gemma2.final_logit_softcapping f32              = 30.000000\n",
      "llama_model_loader: - kv  19:            gemma2.attention.sliding_window u32              = 4096\n",
      "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,256000]  = [\"<pad>\", \"<eos>\", \"<bos>\", \"<unk>\", ...\n",
      "llama_model_loader: - kv  23:                      tokenizer.ggml.scores arr[f32,256000]  = [-1000.000000, -1000.000000, -1000.00...\n",
      "llama_model_loader: - kv  24:                  tokenizer.ggml.token_type arr[i32,256000]  = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\n",
      "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 2\n",
      "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 1\n",
      "llama_model_loader: - kv  27:            tokenizer.ggml.unknown_token_id u32              = 3\n",
      "llama_model_loader: - kv  28:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  29:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  30:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  31:                    tokenizer.chat_template str              = {% if messages[0]['role'] == 'system'...\n",
      "llama_model_loader: - kv  32:            tokenizer.ggml.add_space_prefix bool             = false\n",
      "llama_model_loader: - kv  33:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:  105 tensors\n",
      "llama_model_loader: - type bf16:  183 tensors\n",
      "[   1/ 288]                    token_embd.weight - [ 2304, 256000,     1,     1], type =   bf16, converting to q6_K .. size =  1125.00 MiB ->   461.43 MiB\n",
      "[   2/ 288]               blk.0.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[   3/ 288]                blk.0.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[   4/ 288]                blk.0.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[   5/ 288]                  blk.0.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[   6/ 288]     blk.0.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[   7/ 288]           blk.0.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[   8/ 288]                blk.0.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[   9/ 288]                  blk.0.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[  10/ 288]             blk.0.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[  11/ 288]                  blk.0.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[  12/ 288]                  blk.0.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[  13/ 288]               blk.1.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  14/ 288]                blk.1.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[  15/ 288]                blk.1.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[  16/ 288]                  blk.1.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[  17/ 288]     blk.1.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  18/ 288]           blk.1.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  19/ 288]                blk.1.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  20/ 288]                  blk.1.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[  21/ 288]             blk.1.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[  22/ 288]                  blk.1.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[  23/ 288]                  blk.1.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[  24/ 288]              blk.10.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  25/ 288]               blk.10.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[  26/ 288]               blk.10.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[  27/ 288]                 blk.10.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[  28/ 288]    blk.10.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  29/ 288]          blk.10.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  30/ 288]               blk.10.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  31/ 288]                 blk.10.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[  32/ 288]            blk.10.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[  33/ 288]                 blk.10.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[  34/ 288]                 blk.10.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[  35/ 288]              blk.11.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  36/ 288]               blk.11.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[  37/ 288]               blk.11.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[  38/ 288]                 blk.11.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[  39/ 288]    blk.11.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  40/ 288]          blk.11.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  41/ 288]               blk.11.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  42/ 288]                 blk.11.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[  43/ 288]            blk.11.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[  44/ 288]                 blk.11.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[  45/ 288]                 blk.11.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[  46/ 288]              blk.12.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  47/ 288]               blk.12.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[  48/ 288]               blk.12.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[  49/ 288]                 blk.12.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[  50/ 288]    blk.12.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  51/ 288]          blk.12.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  52/ 288]               blk.12.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  53/ 288]                 blk.12.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[  54/ 288]            blk.12.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[  55/ 288]                 blk.12.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[  56/ 288]                 blk.12.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[  57/ 288]              blk.13.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  58/ 288]               blk.13.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[  59/ 288]               blk.13.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[  60/ 288]                 blk.13.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[  61/ 288]    blk.13.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  62/ 288]          blk.13.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  63/ 288]               blk.13.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  64/ 288]                 blk.13.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[  65/ 288]            blk.13.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[  66/ 288]                 blk.13.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[  67/ 288]                 blk.13.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[  68/ 288]              blk.14.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  69/ 288]               blk.14.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[  70/ 288]               blk.14.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[  71/ 288]                 blk.14.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[  72/ 288]    blk.14.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  73/ 288]          blk.14.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  74/ 288]               blk.14.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  75/ 288]                 blk.14.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[  76/ 288]            blk.14.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[  77/ 288]                 blk.14.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[  78/ 288]                 blk.14.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[  79/ 288]              blk.15.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  80/ 288]               blk.15.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[  81/ 288]               blk.15.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[  82/ 288]                 blk.15.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[  83/ 288]    blk.15.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  84/ 288]          blk.15.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  85/ 288]               blk.15.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  86/ 288]                 blk.15.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[  87/ 288]            blk.15.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[  88/ 288]                 blk.15.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[  89/ 288]                 blk.15.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[  90/ 288]              blk.16.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  91/ 288]               blk.16.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[  92/ 288]               blk.16.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[  93/ 288]                 blk.16.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[  94/ 288]    blk.16.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  95/ 288]          blk.16.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  96/ 288]               blk.16.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[  97/ 288]                 blk.16.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[  98/ 288]            blk.16.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[  99/ 288]                 blk.16.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 100/ 288]                 blk.16.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[ 101/ 288]              blk.17.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 102/ 288]               blk.17.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 103/ 288]               blk.17.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 104/ 288]                 blk.17.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 105/ 288]    blk.17.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 106/ 288]          blk.17.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 107/ 288]               blk.17.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 108/ 288]                 blk.17.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 109/ 288]            blk.17.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 110/ 288]                 blk.17.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 111/ 288]                 blk.17.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 112/ 288]              blk.18.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 113/ 288]               blk.18.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 114/ 288]               blk.18.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 115/ 288]                 blk.18.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 116/ 288]    blk.18.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 117/ 288]          blk.18.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 118/ 288]               blk.18.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 119/ 288]                 blk.18.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 120/ 288]            blk.18.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 121/ 288]                 blk.18.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 122/ 288]                 blk.18.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 123/ 288]              blk.19.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 124/ 288]               blk.19.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[ 125/ 288]               blk.19.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 126/ 288]                 blk.19.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 127/ 288]    blk.19.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 128/ 288]          blk.19.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 129/ 288]               blk.19.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 130/ 288]                 blk.19.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 131/ 288]            blk.19.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 132/ 288]                 blk.19.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 133/ 288]                 blk.19.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[ 134/ 288]               blk.2.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 135/ 288]                blk.2.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 136/ 288]                blk.2.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 137/ 288]                  blk.2.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 138/ 288]     blk.2.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 139/ 288]           blk.2.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 140/ 288]                blk.2.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 141/ 288]                  blk.2.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 142/ 288]             blk.2.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 143/ 288]                  blk.2.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 144/ 288]                  blk.2.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 145/ 288]              blk.20.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 146/ 288]               blk.20.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 147/ 288]               blk.20.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 148/ 288]                 blk.20.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 149/ 288]    blk.20.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 150/ 288]          blk.20.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 151/ 288]               blk.20.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 152/ 288]                 blk.20.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 153/ 288]            blk.20.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 154/ 288]                 blk.20.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 155/ 288]                 blk.20.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 156/ 288]              blk.21.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 157/ 288]               blk.21.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[ 158/ 288]               blk.21.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 159/ 288]                 blk.21.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 160/ 288]    blk.21.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 161/ 288]          blk.21.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 162/ 288]               blk.21.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 163/ 288]                 blk.21.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 164/ 288]            blk.21.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 165/ 288]                 blk.21.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 166/ 288]                 blk.21.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[ 167/ 288]              blk.22.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 168/ 288]               blk.22.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 169/ 288]               blk.22.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 170/ 288]                 blk.22.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 171/ 288]    blk.22.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 172/ 288]          blk.22.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 173/ 288]               blk.22.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 174/ 288]                 blk.22.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 175/ 288]            blk.22.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 176/ 288]                 blk.22.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 177/ 288]                 blk.22.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 178/ 288]              blk.23.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 179/ 288]               blk.23.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 180/ 288]               blk.23.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 181/ 288]                 blk.23.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 182/ 288]    blk.23.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 183/ 288]          blk.23.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 184/ 288]               blk.23.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 185/ 288]                 blk.23.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 186/ 288]            blk.23.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 187/ 288]                 blk.23.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 188/ 288]                 blk.23.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 189/ 288]               blk.24.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 190/ 288]                 blk.24.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 191/ 288]            blk.24.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 192/ 288]                 blk.24.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 193/ 288]                 blk.24.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[ 194/ 288]               blk.3.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 195/ 288]                blk.3.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[ 196/ 288]                blk.3.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 197/ 288]                  blk.3.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 198/ 288]     blk.3.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 199/ 288]           blk.3.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 200/ 288]                blk.3.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 201/ 288]                  blk.3.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 202/ 288]             blk.3.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 203/ 288]                  blk.3.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 204/ 288]                  blk.3.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 205/ 288]               blk.4.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 206/ 288]                blk.4.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 207/ 288]                blk.4.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 208/ 288]                  blk.4.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 209/ 288]     blk.4.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 210/ 288]           blk.4.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 211/ 288]                blk.4.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 212/ 288]                  blk.4.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 213/ 288]             blk.4.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 214/ 288]                  blk.4.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 215/ 288]                  blk.4.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 216/ 288]               blk.5.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 217/ 288]                blk.5.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 218/ 288]                blk.5.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 219/ 288]                  blk.5.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 220/ 288]     blk.5.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 221/ 288]           blk.5.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 222/ 288]                blk.5.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 223/ 288]                  blk.5.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 224/ 288]             blk.5.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 225/ 288]                  blk.5.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 226/ 288]                  blk.5.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[ 227/ 288]               blk.6.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 228/ 288]                blk.6.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[ 229/ 288]                blk.6.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 230/ 288]                  blk.6.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 231/ 288]     blk.6.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 232/ 288]           blk.6.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 233/ 288]                blk.6.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 234/ 288]                  blk.6.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 235/ 288]             blk.6.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 236/ 288]                  blk.6.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 237/ 288]                  blk.6.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 238/ 288]               blk.7.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 239/ 288]                blk.7.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 240/ 288]                blk.7.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 241/ 288]                  blk.7.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 242/ 288]     blk.7.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 243/ 288]           blk.7.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 244/ 288]                blk.7.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 245/ 288]                  blk.7.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 246/ 288]             blk.7.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 247/ 288]                  blk.7.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 248/ 288]                  blk.7.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[ 249/ 288]               blk.8.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 250/ 288]                blk.8.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[ 251/ 288]                blk.8.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 252/ 288]                  blk.8.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 253/ 288]     blk.8.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 254/ 288]           blk.8.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 255/ 288]                blk.8.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 256/ 288]                  blk.8.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 257/ 288]             blk.8.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 258/ 288]                  blk.8.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 259/ 288]                  blk.8.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[ 260/ 288]               blk.9.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 261/ 288]                blk.9.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[ 262/ 288]                blk.9.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 263/ 288]                  blk.9.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 264/ 288]     blk.9.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 265/ 288]           blk.9.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 266/ 288]                blk.9.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 267/ 288]                  blk.9.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 268/ 288]             blk.9.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 269/ 288]                  blk.9.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 270/ 288]                  blk.9.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[ 271/ 288]              blk.24.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 272/ 288]               blk.24.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[ 273/ 288]                 blk.24.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 274/ 288]    blk.24.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 275/ 288]          blk.24.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 276/ 288]               blk.24.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 277/ 288]              blk.25.attn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 278/ 288]               blk.25.ffn_down.weight - [ 9216,  2304,     1,     1], type =   bf16, converting to q6_K .. size =    40.50 MiB ->    16.61 MiB\n",
      "[ 279/ 288]               blk.25.ffn_gate.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 280/ 288]                 blk.25.ffn_up.weight - [ 2304,  9216,     1,     1], type =   bf16, converting to q5_K .. size =    40.50 MiB ->    13.92 MiB\n",
      "[ 281/ 288]    blk.25.post_attention_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 282/ 288]          blk.25.post_ffw_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 283/ 288]               blk.25.ffn_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "[ 284/ 288]                 blk.25.attn_k.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q5_K .. size =     4.50 MiB ->     1.55 MiB\n",
      "[ 285/ 288]            blk.25.attn_output.weight - [ 2048,  2304,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 286/ 288]                 blk.25.attn_q.weight - [ 2304,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     9.00 MiB ->     3.09 MiB\n",
      "[ 287/ 288]                 blk.25.attn_v.weight - [ 2304,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     4.50 MiB ->     1.85 MiB\n",
      "[ 288/ 288]                   output_norm.weight - [ 2304,     1,     1,     1], type =    f32, size =    0.009 MB\n",
      "llama_model_quantize_internal: model size  =  4986.92 MB\n",
      "llama_model_quantize_internal: quant size  =  1828.42 MB\n",
      "\n",
      "main: quantize time =  7646.46 ms\n",
      "main:    total time =  7646.46 ms\n",
      "Unsloth: Conversion completed! Output location: ./simpler-gemma-2-2b-multi/unsloth.Q5_K_M.gguf\n",
      "Unsloth: Uploading GGUF to Huggingface Hub...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496bb7f35baa48ed983f8c967d1cb06b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unsloth.BF16.gguf:   0%|          | 0.00/5.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved GGUF to https://huggingface.co/davidbzyk/simpler-gemma-2-2b-multi\n",
      "Unsloth: Uploading GGUF to Huggingface Hub...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1781362ed04067a33f254c560e5c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unsloth.Q4_K_M.gguf:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved GGUF to https://huggingface.co/davidbzyk/simpler-gemma-2-2b-multi\n",
      "Unsloth: Uploading GGUF to Huggingface Hub...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e39d71fd8b45d895949bdc8efec5d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unsloth.Q8_0.gguf:   0%|          | 0.00/2.78G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved GGUF to https://huggingface.co/davidbzyk/simpler-gemma-2-2b-multi\n",
      "Unsloth: Uploading GGUF to Huggingface Hub...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8249060322496d95080c6f09e4038a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unsloth.Q5_K_M.gguf:   0%|          | 0.00/1.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "Unsloth: ##### The current model auto adds a BOS token.\n",
      "Unsloth: ##### We removed it in GGUF's chat template for you.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved GGUF to https://huggingface.co/davidbzyk/simpler-gemma-2-2b-multi\n"
     ]
    }
   ],
   "source": [
    "multi_model = 'simpler-gemma-2-2b-multi'\n",
    "if True:\n",
    "    model.push_to_hub_gguf(\n",
    "        multi_model, # Change hf to your username!\n",
    "        tokenizer,\n",
    "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
    "        token=HUGGING_FACE_HUB_TOKEN, # Get a token at https://huggingface.co/settings/tokens\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
