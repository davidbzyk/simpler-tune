{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continued-Pretraining\n",
    "\n",
    "we just concatenate all rows for each item in every column to build the pretraining set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./processed/pretrain.jsonl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '../raw-data/simplerrawdata.csv'\n",
    "df = pd.read_csv(file_path, header=None)\n",
    "\n",
    "# Function to generate the desired JSONL format\n",
    "def generate_jsonl_format(df):\n",
    "    jsonl_data = []\n",
    "    \n",
    "    for col in range(4, df.shape[1]):  # Starting from column E (index 4)\n",
    "        product = f\"Simpler Trading Product: {df.iloc[3, col]}\"  # E4 (index 3 - 1)\n",
    "        body = (\n",
    "            f\"{df.iloc[3, col]}\\n\\n\"  # E4\n",
    "            f\"By: \\n{df.iloc[4, col]}\\n\\n\"  # E5\n",
    "            f\"Available on: \\n{df.iloc[5, col]}\\n\\n\"  # E6\n",
    "            f\"This product is designed for: \\n{df.iloc[6, col]}\\n\\n\"  # E7\n",
    "            f\"{df.iloc[7, col]}\\n\\n\"  # E8\n",
    "            f\"{df.iloc[11, col]}\\n\\n\"  # E12\n",
    "            f\"{df.iloc[12, col]}\\n\\n\"  # E13\n",
    "            f\"{df.iloc[13, col]}\\n\\n\"  # E14\n",
    "            f\"{df.iloc[14, col]}\\n\\n\"  # E15\n",
    "            f\"{df.iloc[15, col]}\\n\\n\"  # E16\n",
    "            f\"{df.iloc[16, col]}\\n\\n\"  # E17\n",
    "            f\"{df.iloc[17, col]}\\n\\n\"  # E18\n",
    "            f\"{df.iloc[18, col]}\\n\\n\"  # E19\n",
    "            f\"{df.iloc[19, col]}\\n\\n\"  # E20\n",
    "            f\"{df.iloc[20, col]}\\n\\n\"  # E21\n",
    "            f\"{df.iloc[21, col]}\\n\\n\"  # E22\n",
    "            f\"{df.iloc[22, col]}\\n\\n\"  # E23\n",
    "            f\"{df.iloc[23, col]}\\n\\n\"  # E24\n",
    "            f\"{df.iloc[24, col]}\\n\\n\"  # E25\n",
    "            f\"{df.iloc[25, col]}\\n\\n\"  # E26\n",
    "            f\"{df.iloc[26, col]}\\n\\n\"  # E27\n",
    "            f\"{df.iloc[27, col]}\\n\\n\"  # E28\n",
    "            f\"{df.iloc[28, col]}\\n\\n\"  # E29\n",
    "            f\"{df.iloc[29, col]}\\n\\n\"  # E30\n",
    "            f\"{df.iloc[30, col]}\\n\\n\"  # E31\n",
    "            f\"{df.iloc[31, col]}\\n\\n\"  # E32\n",
    "            f\"{df.iloc[32, col]}\\n\\n\"  # E33\n",
    "            f\"{df.iloc[33, col]}\\n\\n\"  # E34\n",
    "            f\"{df.iloc[34, col]}\\n\\n\"  # E35\n",
    "            f\"{df.iloc[35, col]}\\n\\n\"  # E36\n",
    "            f\"{df.iloc[36, col]}\\n\\n\"  # E37\n",
    "            f\"{df.iloc[37, col]}\\n\\n\"  # E38\n",
    "            f\"{df.iloc[38, col]}\\n\\n\"  # E39\n",
    "            f\"{df.iloc[3, col]} Testimonials: \\n\\n\"  # E4\n",
    "            f\"{df.iloc[39, col]}\\n\\n\"  # E40\n",
    "            f\"{df.iloc[40, col]}\\n\\n\"  # E41\n",
    "            f\"{df.iloc[41, col]}\\n\\n\"  # E42\n",
    "            f\"{df.iloc[42, col]}\\n\\n\"  # E43\n",
    "            f\"{df.iloc[43, col]}\\n\\n\"  # E44\n",
    "            f\"{df.iloc[44, col]}\\n\\n\"  # E45\n",
    "            f\"{df.iloc[45, col]}\\n\\n\"  # E46\n",
    "            f\"{df.iloc[46, col]}\\n\\n\"  # E47\n",
    "            f\"{df.iloc[47, col]}\\n\\n\"  # E48\n",
    "            f\"{df.iloc[48, col]}\\n\\n\"  # E49\n",
    "            f\"{df.iloc[49, col]}\\n\\n\"  # E50\n",
    "            f\"{df.iloc[40, col]}\\n\\n\"  # E51\n",
    "            f\"{df.iloc[3, col]} Frequently Asked Questions: \\n\\n\"  # E4\n",
    "            f\"{df.iloc[51, col]}\\n\\n\"  # E52\n",
    "            f\"{df.iloc[52, col]}\\n\\n\"  # E53\n",
    "            f\"{df.iloc[53, col]}\\n\\n\"  # E54\n",
    "            f\"{df.iloc[54, col]}\\n\\n\"  # E55\n",
    "            f\"{df.iloc[55, col]}\\n\\n\"  # E56\n",
    "            f\"{df.iloc[56, col]}\\n\\n\"  # E57\n",
    "            f\"{df.iloc[57, col]}\\n\\n\"  # E58\n",
    "            f\"{df.iloc[58, col]}\\n\\n\"  # E59\n",
    "        )\n",
    "\n",
    "        jsonl_data.append({\"product\": product, \"body\": body})\n",
    "    \n",
    "    return jsonl_data\n",
    "\n",
    "# Generate the JSONL data\n",
    "jsonl_data = generate_jsonl_format(df)\n",
    "\n",
    "# Save the data to a JSONL file\n",
    "output_file_path = './processed/pretrain.jsonl'\n",
    "with open(output_file_path, 'w') as outfile:\n",
    "    for item in jsonl_data:\n",
    "        json.dump(item, outfile)\n",
    "        outfile.write('\\n')\n",
    "\n",
    "# Output the path of the generated file\n",
    "print(output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean miscellaneous nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned file saved as ./cleaned/cleaned_pretrain.jsonl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./cleaned/cleaned_pretrain.jsonl'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def clean_nan_in_body(input_file, output_file):\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            # Parse the JSON object\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            # Clean the 'body' key if it exists\n",
    "            if 'body' in data:\n",
    "                body = data['body']\n",
    "                # Remove \"\\nnan\\n\" first, then \"nan\"\n",
    "                body = body.replace(\"\\nnan\\n\", \"\").replace(\"nan\", \"\")\n",
    "                data['body'] = body\n",
    "            \n",
    "            # Write the cleaned JSON object back to the output file\n",
    "            outfile.write(json.dumps(data) + '\\n')\n",
    "    \n",
    "    print(f\"Cleaned file saved as {output_file}\")\n",
    "\n",
    "# Define input and output file paths\n",
    "input_file_path = './processed/pretrain.jsonl'\n",
    "output_file_path = './cleaned/cleaned_pretrain.jsonl'\n",
    "\n",
    "# Run the cleanup function\n",
    "clean_nan_in_body(input_file_path, output_file_path)\n",
    "\n",
    "# Output the path of the cleaned file\n",
    "output_file_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine `max_seq_length` set a cutoff to save memory we use 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "premac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
